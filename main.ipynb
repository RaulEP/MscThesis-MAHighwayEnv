{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import highway_env\n",
    "import matplotlib.pyplot as plt \n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "\n",
    "env = gym.make('ma-highway-v0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n",
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.configure(  {\n",
    "                \"speed_limit\": 20,\n",
    "                \"vehicles_density\": 1,\n",
    "                \"ego_spacing\": 1,\n",
    "                \"road_length\":10000, \n",
    "                \"simulation_frequency\":15, \n",
    "                \"duration\":40,\n",
    "                \"DLC_config\": {\n",
    "                    \"count\": 5,\n",
    "                    \"reward_speed_range\": [20, 40],\n",
    "                    \"weights\": [10,5,1,1],\n",
    "                        },\n",
    "                \"MLC_config\": {\n",
    "                    \"count\":10 ,\n",
    "                    \"reward_speed_range\": [20, 30],\n",
    "                    \"weights\": [10,5,1,1]\n",
    "                        } \n",
    "                })\n",
    "env.reset()\n",
    "plt.imshow(env.render(mode=\"rgb_array\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Visualization utils\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18088), started 0:00:03 ago. (Use '!kill 18088' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b600d22a144ef822\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b600d22a144ef822\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"highway_a2c/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to highway_a2c/A2C_3\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.45     |\n",
      "|    ep_rew_mean        | 2.22     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -21.1    |\n",
      "|    explained_variance | 0.374    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.422   |\n",
      "|    value_loss         | 0.239    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.02     |\n",
      "|    ep_rew_mean        | 2.83     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 540      |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.8    |\n",
      "|    explained_variance | 0.544    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.321    |\n",
      "|    value_loss         | 0.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.67     |\n",
      "|    ep_rew_mean        | 3.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 797      |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.14    |\n",
      "|    explained_variance | 0.0813   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.237    |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.4      |\n",
      "|    ep_rew_mean        | 4.3      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 1048     |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.54    |\n",
      "|    explained_variance | 0.429    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.188    |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.47     |\n",
      "|    ep_rew_mean        | 5.36     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 1296     |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.35    |\n",
      "|    explained_variance | 0.678    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -1.95    |\n",
      "|    value_loss         | 0.255    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.53     |\n",
      "|    ep_rew_mean        | 5.44     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 1547     |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.2     |\n",
      "|    explained_variance | -0.766   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.502   |\n",
      "|    value_loss         | 1.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.06     |\n",
      "|    ep_rew_mean        | 4.99     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 1802     |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.92    |\n",
      "|    explained_variance | 0.915    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -3.44    |\n",
      "|    value_loss         | 0.0827   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.97     |\n",
      "|    ep_rew_mean        | 4.89     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 2056     |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.27    |\n",
      "|    explained_variance | 0.201    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -1.28    |\n",
      "|    value_loss         | 0.788    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.15     |\n",
      "|    ep_rew_mean        | 4.05     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 2314     |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.62    |\n",
      "|    explained_variance | 0.369    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 2.61     |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.18     |\n",
      "|    ep_rew_mean        | 4.07     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 2573     |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.32    |\n",
      "|    explained_variance | 0.89     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.364    |\n",
      "|    value_loss         | 0.341    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.41     |\n",
      "|    ep_rew_mean        | 4.3      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 2831     |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.66    |\n",
      "|    explained_variance | 0.889    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -1.35    |\n",
      "|    value_loss         | 0.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.74     |\n",
      "|    ep_rew_mean        | 4.62     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 3086     |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.28    |\n",
      "|    explained_variance | 0.496    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.834    |\n",
      "|    value_loss         | 0.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.07     |\n",
      "|    ep_rew_mean        | 3.94     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 3342     |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.95    |\n",
      "|    explained_variance | 0.713    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.24    |\n",
      "|    value_loss         | 0.389    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.82     |\n",
      "|    ep_rew_mean        | 4.72     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 3595     |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.67    |\n",
      "|    explained_variance | 0.866    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    value_loss         | 0.185    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.33     |\n",
      "|    ep_rew_mean        | 4.22     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 3848     |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.86    |\n",
      "|    explained_variance | 0.93     |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.157    |\n",
      "|    value_loss         | 0.939    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.7      |\n",
      "|    ep_rew_mean        | 4.6      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 4100     |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.8     |\n",
      "|    explained_variance | 0.817    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.459    |\n",
      "|    value_loss         | 0.168    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.96     |\n",
      "|    ep_rew_mean        | 4.85     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 4350     |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.23    |\n",
      "|    explained_variance | 0.879    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.33     |\n",
      "|    value_loss         | 0.0989   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.68     |\n",
      "|    ep_rew_mean        | 4.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 4601     |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5       |\n",
      "|    explained_variance | 0.923    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.328    |\n",
      "|    value_loss         | 0.178    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.47     |\n",
      "|    ep_rew_mean        | 3.33     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 4859     |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.6    |\n",
      "|    explained_variance | 0.366    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    value_loss         | 0.359    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.32     |\n",
      "|    ep_rew_mean        | 3.21     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 5120     |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.1    |\n",
      "|    explained_variance | 0.173    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.484    |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.21     |\n",
      "|    ep_rew_mean        | 3.09     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 5384     |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.03    |\n",
      "|    explained_variance | 0.481    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.909    |\n",
      "|    value_loss         | 0.343    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.18     |\n",
      "|    ep_rew_mean        | 3.07     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 5647     |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.64    |\n",
      "|    explained_variance | -0.199   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.609   |\n",
      "|    value_loss         | 0.864    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.52     |\n",
      "|    ep_rew_mean        | 3.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 5912     |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.63    |\n",
      "|    explained_variance | 0.751    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.95    |\n",
      "|    value_loss         | 0.238    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.38     |\n",
      "|    ep_rew_mean        | 3.3      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 6178     |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.57    |\n",
      "|    explained_variance | 0.804    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.337   |\n",
      "|    value_loss         | 2.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.59     |\n",
      "|    ep_rew_mean        | 3.52     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 6443     |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.3     |\n",
      "|    explained_variance | 0.789    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.194    |\n",
      "|    value_loss         | 0.265    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.64     |\n",
      "|    ep_rew_mean        | 3.56     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 6705     |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.68    |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.578    |\n",
      "|    value_loss         | 0.0319   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.92     |\n",
      "|    ep_rew_mean        | 3.86     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 6955     |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.57    |\n",
      "|    explained_variance | 0.548    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.718   |\n",
      "|    value_loss         | 0.452    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.89     |\n",
      "|    ep_rew_mean        | 3.8      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 7206     |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 0.911    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.808   |\n",
      "|    value_loss         | 0.0632   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.83     |\n",
      "|    ep_rew_mean        | 3.72     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 7461     |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0.679    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.147    |\n",
      "|    value_loss         | 0.807    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42     |\n",
      "|    ep_rew_mean        | 3.29     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 7712     |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | -0.324   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.176   |\n",
      "|    value_loss         | 0.457    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.57     |\n",
      "|    ep_rew_mean        | 3.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 7956     |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | 0.966    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    value_loss         | 0.026    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.07     |\n",
      "|    ep_rew_mean        | 2.93     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 8212     |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | 0.419    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.00568  |\n",
      "|    value_loss         | 0.393    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.04     |\n",
      "|    ep_rew_mean        | 3.85     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 8463     |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.27    |\n",
      "|    explained_variance | 0.685    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -2.21    |\n",
      "|    value_loss         | 0.146    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.48     |\n",
      "|    ep_rew_mean        | 5.21     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 8703     |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4       |\n",
      "|    explained_variance | 0.648    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.714    |\n",
      "|    value_loss         | 0.535    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.1      |\n",
      "|    ep_rew_mean        | 5.73     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 8941     |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.94    |\n",
      "|    explained_variance | 0.356    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 1.39     |\n",
      "|    value_loss         | 0.527    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.06     |\n",
      "|    ep_rew_mean        | 4.7      |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 9182     |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.82    |\n",
      "|    explained_variance | 0.959    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.895    |\n",
      "|    value_loss         | 0.539    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.83     |\n",
      "|    ep_rew_mean        | 5.46     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 9427     |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.5     |\n",
      "|    explained_variance | 0.948    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    value_loss         | 0.233    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.17     |\n",
      "|    ep_rew_mean        | 4.84     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 9671     |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.15    |\n",
      "|    explained_variance | 0.855    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.787    |\n",
      "|    value_loss         | 0.455    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.22     |\n",
      "|    ep_rew_mean        | 3.92     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 9917     |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.17    |\n",
      "|    explained_variance | 0.659    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.253    |\n",
      "|    value_loss         | 0.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.64     |\n",
      "|    ep_rew_mean        | 4.36     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1        |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 10166    |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.69    |\n",
      "|    explained_variance | 0.345    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -1.1     |\n",
      "|    value_loss         | 0.212    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x1a2327bb0c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "#MODEL TRAINING\n",
    "A2C_path = os.path.join('Training', 'Saved Models', 'A2C_model')\n",
    "\n",
    "model = A2C('MultiInputPolicy', env,\n",
    "            policy_kwargs=dict(net_arch=[256, 256]),\n",
    "            learning_rate=5e-4,\n",
    "            gamma=0.8,\n",
    "            verbose=1,\n",
    "            tensorboard_log=\"highway_a2c/\",\n",
    "            normalize_advantage=True)\n",
    "\n",
    "model.learn(total_timesteps=int(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL SAVING\n",
    "model.save(A2C_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60528c1aac94a5abbf958233fa9731d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'speed': 23.102962356710236, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.09270364821226292, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.30367138233337376, 1]}, {'proactive_dlc_reward': [0.6826413557465724, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3652827114931448, 1]}, {'proactive_mlc_reward': [0.13125401937431927, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5155776249096305, 1]}, {'proactive_dlc_reward': [0.68100838719756, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36201677439512, 1]}, {'proactive_mlc_reward': [0.16771097032442447, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3236214456823582, 1]}, {'proactive_dlc_reward': [0.6787046033838943, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3574092067677885, 1]}, {'proactive_mlc_reward': [0.20179834622051113, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12278001101378529, 1]}, {'proactive_dlc_reward': [0.7841765587168237, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.5661267644163092, 1]}, {'proactive_mlc_reward': [0.23909866992119558, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.31475780512965273, 1]}, {'proactive_dlc_reward': [0.6827228446604792, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36544568932095844, 1]}, {'proactive_mlc_reward': [0.2759888094825955, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12354110824402902, 1]}, {'proactive_mlc_reward': [0.2930119479093115, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3037529688232453, 1]}, {'proactive_mlc_reward': [0.3111527540793432, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.514959327713779, 1]}, {'proactive_mlc_reward': [0.32775024059176483, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12888270798239637, 1]}, {'proactive_mlc_reward': [0.3453388862786714, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.29665367810080634, 1]}]}\n",
      "{'speed': 24.650047932422606, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.11676668314699425, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4649459227436196, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.271266538060358, 1]}, {'proactive_mlc_reward': [0.158883661975122, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9106371914425253, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27066406111738656, 1]}, {'proactive_mlc_reward': [0.19184792139690823, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46746293360171265, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2698140896772358, 1]}, {'proactive_mlc_reward': [0.22239912876596177, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.022649586772003617, 1]}, {'proactive_dlc_reward': [0.8582455348611726, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7164845012029708, 1]}, {'proactive_mlc_reward': [0.2631922497601273, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4658278319743651, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2712966030556494, 1]}, {'proactive_mlc_reward': [0.296593316200471, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.022789988598131927, 1]}, {'proactive_mlc_reward': [0.3170516792959273, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4637977377206216, 1]}, {'proactive_mlc_reward': [0.3387793712514939, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9105231323552783, 1]}, {'proactive_mlc_reward': [0.3483808846251617, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.023775369082922992, 1]}, {'proactive_mlc_reward': [0.36936762000461537, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4636507146406643, 1]}]}\n",
      "{'speed': 24.93544332130947, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.1415953767607211, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49354394527858786, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05004132954059859, 1]}, {'proactive_mlc_reward': [0.18880540431215959, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.049930188861547896, 1]}, {'proactive_mlc_reward': [0.21668871224379888, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4939977924532709, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04977339215067857, 1]}, {'proactive_mlc_reward': [0.2423677292868754, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.8719092549442937, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7438185075584623, 1]}, {'proactive_mlc_reward': [0.2880250397890541, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4936961604866024, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05004687571797799, 1]}, {'proactive_mlc_reward': [0.31656277147573225, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3418745357437831, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49332166307797853, 1]}, {'proactive_mlc_reward': [0.3643977781141476, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3694231054440518, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3941899727472035, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49330485361210774, 1]}]}\n",
      "{'speed': 23.121698744323467, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 4, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.0945870600040491, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.31216987443234673, 1]}, {'proactive_dlc_reward': [0.6803764086963555, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36075281739271114, 1]}, {'proactive_mlc_reward': [0.13054165795312192, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.525342304066385, 1]}, {'proactive_dlc_reward': [0.6829496771356584, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36589935427131676, 1]}, {'proactive_mlc_reward': [0.16685783028331613, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.31964551060497043, 1]}, {'proactive_dlc_reward': [0.6784631843207933, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.35692636864158656, 1]}, {'proactive_mlc_reward': [0.20110824250194706, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.09421862594856165, 1]}, {'proactive_dlc_reward': [0.6816889011335959, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3633778022671919, 1]}, {'proactive_mlc_reward': [0.24224851013165533, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3225567680831187, 1]}, {'proactive_dlc_reward': [0.6835366700951402, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3670733401902805, 1]}, {'proactive_mlc_reward': [0.2807860261906398, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.1249711152183206, 1]}, {'proactive_mlc_reward': [0.2996116036697142, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.32987703567531523, 1]}, {'proactive_mlc_reward': [0.32079836586783633, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5181938290007636, 1]}, {'proactive_mlc_reward': [0.3374073479795703, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10719180331941125, 1]}, {'proactive_mlc_reward': [0.3574236132654577, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.31398610755040934, 1]}]}\n",
      "{'speed': 24.65350428849829, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.11866797667754417, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.465350428849829, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27043089528228226, 1]}, {'proactive_mlc_reward': [0.15821908071578367, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9124385102894248, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2713802919523495, 1]}, {'proactive_mlc_reward': [0.1906517520163855, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4600088497763764, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26972501911969254, 1]}, {'proactive_mlc_reward': [0.22156926954909303, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.017380784757555647, 1]}, {'proactive_dlc_reward': [0.737398452333647, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.47203429424317117, 1]}, {'proactive_mlc_reward': [0.2660567894031868, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46054271376565126, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2715968605592513, 1]}, {'proactive_mlc_reward': [0.3013975301650142, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.023053786155904633, 1]}, {'proactive_mlc_reward': [0.32377916436055715, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.46861692053480974, 1]}, {'proactive_mlc_reward': [0.34844080998038585, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9111198102424914, 1]}, {'proactive_mlc_reward': [0.3579318548917131, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.01977398462896396, 1]}, {'proactive_mlc_reward': [0.3815134170627345, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46568547467093707, 1]}]}\n",
      "{'speed': 24.936080925396702, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.14349843069540508, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4936080925396702, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04988717607981848, 1]}, {'proactive_mlc_reward': [0.18815111734581672, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05006231405286634, 1]}, {'proactive_mlc_reward': [0.2154831405681351, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49400062466119865, 1]}, {'proactive_dlc_reward': [-1, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2415948486556458, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7476753557441971, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49206889200597725, 1]}, {'proactive_mlc_reward': [0.2908907975209537, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49409966312686676, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.050102265095496, 1]}, {'proactive_mlc_reward': [0.32136859141731683, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3486256018530323, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49421067178891465, 1]}, {'proactive_mlc_reward': [0.37836531041843385, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.37792515748309147, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.40634551051424256, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49366989941959327, 1]}]}\n",
      "{'speed': 23.276942408564157, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 4, 1, 4, 0, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.0956791652544668, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.32105324258507617, 1]}, {'proactive_dlc_reward': [0.6841802025132326, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36836040502646517, 1]}, {'proactive_mlc_reward': [0.1381604671848184, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5315477796456503, 1]}, {'proactive_dlc_reward': [0.6844112606390338, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3688225212780676, 1]}, {'proactive_mlc_reward': [0.17195981967045892, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.30185763186002995, 1]}, {'proactive_dlc_reward': [0.682951664569323, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3659033291386461, 1]}, {'proactive_mlc_reward': [0.20857600254081318, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.09966270575480181, 1]}, {'proactive_dlc_reward': [0.6775742146726214, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3551484293452427, 1]}, {'proactive_mlc_reward': [0.24610261198487673, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3167519171921562, 1]}, {'proactive_dlc_reward': [0.6807743679896247, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36154873597924925, 1]}, {'proactive_mlc_reward': [0.2844903762262456, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3253831923617113, 1]}, {'proactive_mlc_reward': [0.3023864192637471, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3112223784675493, 1]}, {'proactive_mlc_reward': [0.3230908357194056, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5221093254969975, 1]}, {'proactive_mlc_reward': [0.34139528230665017, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12691847661764513, 1]}, {'proactive_mlc_reward': [0.3631053680575068, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3216195258058498, 1]}]}\n",
      "{'speed': 24.682142540075155, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.11948002941436026, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4602669973358502, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2718342891638562, 1]}, {'proactive_mlc_reward': [0.16586825434786967, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9135832524704494, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2719195370967489, 1]}, {'proactive_mlc_reward': [0.1960139896642956, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4646111904770951, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2713810252077204, 1]}, {'proactive_mlc_reward': [0.22906366835510564, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.01838507003939398, 1]}, {'proactive_dlc_reward': [0.7366394041199522, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4705156726897449, 1]}, {'proactive_mlc_reward': [0.2702059493381703, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46619569164321356, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2705777207055771, 1]}, {'proactive_mlc_reward': [0.30738279317406286, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26505866391714716, 1]}, {'proactive_mlc_reward': [0.32646269968551983, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4651756415054262, 1]}, {'proactive_mlc_reward': [0.3507524389925734, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9118421133023681, 1]}, {'proactive_mlc_reward': [0.36201631503679493, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.02341302159354939, 1]}, {'proactive_mlc_reward': [0.38690902499021373, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46037084203120493, 1]}]}\n",
      "{'speed': 24.94136390720075, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.14431268466313427, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4940485151475212, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05014606424274994, 1]}, {'proactive_mlc_reward': [0.1958068330242682, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.050161790177592105, 1]}, {'proactive_mlc_reward': [0.220841044555257, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4934821549263205, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05006244931862334, 1]}, {'proactive_mlc_reward': [0.2490484288669095, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7475353319061288, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49178993517097586, 1]}, {'proactive_mlc_reward': [0.2950405393642335, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49376402063273445, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04991426139393269, 1]}, {'proactive_mlc_reward': [0.3286800337768806, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04890877805319001, 1]}, {'proactive_mlc_reward': [0.3512922984405021, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4935758490084051, 1]}, {'proactive_mlc_reward': [0.3779717781823906, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.07356290260950686, 1]}, {'proactive_mlc_reward': [0.3829717781823906, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.411742189782343, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49406777952973757, 1]}]}\n",
      "{'speed': 23.079528478621903, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.09334286994374343, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3013306708986125, 1]}, {'proactive_dlc_reward': [0.679136247781656, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3582724955633122, 1]}, {'proactive_mlc_reward': [0.13119260940817298, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5281581576620539, 1]}, {'proactive_dlc_reward': [0.6832765826479702, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36655316529594034, 1]}, {'proactive_mlc_reward': [0.16716367030603338, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.30715822987621133, 1]}, {'proactive_dlc_reward': [0.6777132909615858, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3554265819231716, 1]}, {'proactive_mlc_reward': [0.2037489262601222, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12121701226533758, 1]}, {'proactive_dlc_reward': [0.7856726688690527, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.5691105810313374, 1]}, {'proactive_mlc_reward': [0.24152029843831044, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3016359814970695, 1]}, {'proactive_dlc_reward': [0.6770665900052804, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3541331800105608, 1]}, {'proactive_mlc_reward': [0.2759037928370009, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.107445208543324, 1]}, {'proactive_mlc_reward': [0.29466807807486467, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3179603058007924, 1]}, {'proactive_mlc_reward': [0.31580718141113084, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5221653469635374, 1]}, {'proactive_mlc_reward': [0.33124348469734843, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10484446126907443, 1]}, {'proactive_mlc_reward': [0.3502590618743633, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3229325052598558, 1]}]}\n",
      "{'speed': 24.645725016576744, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.11739446430532849, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46451393606169267, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26997334307949605, 1]}, {'proactive_mlc_reward': [0.15888381060005008, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9129579590158567, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2715009023791806, 1]}, {'proactive_mlc_reward': [0.19089602028815314, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4577190476023027, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26944834908897786, 1]}, {'proactive_mlc_reward': [0.22434206079871186, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.022361255833725124, 1]}, {'proactive_dlc_reward': [0.8585215266649978, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7144112177997158, 1]}, {'proactive_mlc_reward': [0.26554967106193195, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46340721089346565, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26920975146540016, 1]}, {'proactive_mlc_reward': [0.2964295397020821, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.019820731029783545, 1]}, {'proactive_mlc_reward': [0.31877732826998156, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4664186066146293, 1]}, {'proactive_mlc_reward': [0.34346905880643785, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9118524477457118, 1]}, {'proactive_mlc_reward': [0.3517565056833994, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.01934096359391333, 1]}, {'proactive_mlc_reward': [0.37406919425510654, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46061161682030693, 1]}]}\n",
      "{'speed': 24.934645860413752, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.14222104307468314, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49346420208382435, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04980277009032399, 1]}, {'proactive_mlc_reward': [0.1888188158091301, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05008456341011556, 1]}, {'proactive_mlc_reward': [0.2157161715910283, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4935757557395103, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.049705922917524605, 1]}, {'proactive_mlc_reward': [0.24430890598545504, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.8719601679573936, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7439049550202708, 1]}, {'proactive_mlc_reward': [0.2903706165985624, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4932496214550344, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04966190811793077, 1]}, {'proactive_mlc_reward': [0.3164231297924029, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.34361300905522285, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49380514240773793, 1]}, {'proactive_mlc_reward': [0.367742990861627, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.37279942593371596, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.39890354045648196, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.494112444998197, 1]}]}\n",
      "{'speed': 23.252485184763987, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 4, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.09623178486032725, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.32524851847639874, 1]}, {'proactive_dlc_reward': [0.6815805341184749, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3631610682369498, 1]}, {'proactive_mlc_reward': [0.13414160830738114, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5033894951256463, 1]}, {'proactive_dlc_reward': [0.6783664291270655, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3567328582541309, 1]}, {'proactive_mlc_reward': [0.16724605699650066, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.2965634985618305, 1]}, {'proactive_dlc_reward': [0.6845951470709197, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36919029414183946, 1]}, {'proactive_mlc_reward': [0.20292636241618026, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10457925242027563, 1]}, {'proactive_dlc_reward': [0.6795852271595757, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3591704543191513, 1]}, {'proactive_mlc_reward': [0.24015156965068576, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3076916486150488, 1]}, {'proactive_dlc_reward': [0.6838279663246466, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36765593264929314, 1]}, {'proactive_mlc_reward': [0.2779770354439553, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.11485344489706506, 1]}, {'proactive_mlc_reward': [0.2962938458612406, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3166837384406559, 1]}, {'proactive_mlc_reward': [0.3169921569572995, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.52944532680301, 1]}, {'proactive_mlc_reward': [0.33482116073811913, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12136069017305573, 1]}, {'proactive_mlc_reward': [0.354281079768888, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.30989292155606735, 1]}]}\n",
      "{'speed': 24.677630844660815, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 4, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.1203766974643892, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4677630844660815, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2708751523402103, 1]}, {'proactive_mlc_reward': [0.16171161240859871, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9083888115893923, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26968932169406246, 1]}, {'proactive_mlc_reward': [0.19127434991926762, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46363406953968606, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2719873812296951, 1]}, {'proactive_mlc_reward': [0.22343808569223808, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.019292039743980284, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27013899215046566, 1]}, {'proactive_mlc_reward': [0.2638865493701539, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45781685755542156, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27170433308954517, 1]}, {'proactive_mlc_reward': [0.2985390320133423, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.02118734999924037, 1]}, {'proactive_mlc_reward': [0.32039684960482434, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4661831145100518, 1]}, {'proactive_mlc_reward': [0.34468965647694627, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9131954068618668, 1]}, {'proactive_mlc_reward': [0.35541499831605855, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.022387760516460277, 1]}, {'proactive_mlc_reward': [0.3783508549419582, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46493039271103703, 1]}]}\n",
      "{'speed': 24.940531621587393, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.1452189569982332, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4940531621587393, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04996912947515941, 1]}, {'proactive_mlc_reward': [0.19165899217824744, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.049750375836883444, 1]}, {'proactive_mlc_reward': [0.21609662117307288, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49330178095716165, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05017430558269283, 1]}, {'proactive_mlc_reward': [0.2434284242341428, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.25043099054057, 1]}, {'proactive_mlc_reward': [0.28870718073332235, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.493593907010775, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05012209086664896, 1]}, {'proactive_mlc_reward': [0.3185410270610828, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.34523137808893073, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4937617004922938, 1]}, {'proactive_mlc_reward': [0.3746260186682742, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.37538200486105067, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4031792536547369, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4935306072479314, 1]}]}\n",
      "{'speed': 24.989029694769318, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.17018985815432416, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4989029694769318, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.22167707042826515, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.24106384711406006, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49876442740077104, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.26342225522388246, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.25064530983375943, 1]}, {'proactive_mlc_reward': [0.3136761542092266, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49883372647297397, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.33853910264409726, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.37020085307572564, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4988492026931507, 1]}, {'proactive_mlc_reward': [0.40463422011332056, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3953655495655279, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.42814759786473505, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49880657224828084, 1]}]}\n",
      "{'speed': 24.997976275794514, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.195184490205709, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997976275794514, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2516836652348637, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2660578012652977, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997720707346449, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.28342000481637486, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.25012611964217496, 1]}, {'proactive_mlc_reward': [0.3386704498315665, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.499784968467112, 1]}, {'proactive_dlc_reward': [-1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3585384006315782, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3951952220375005, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4997877090640138, 1]}, {'proactive_mlc_reward': [0.43463721193741045, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4153595468002502, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4531417582288158, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49977984490149935, 1]}]}\n",
      "{'speed': 24.99962667769276, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.22018349996457, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.499962667769276, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.28168607096960174, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.29105668597041773, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49995795322610126, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.30341918388501976, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.25002332010086176, 1]}, {'proactive_mlc_reward': [0.3636693976629855, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999603332522941, 1]}, {'proactive_dlc_reward': [0.6019158140694751, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.20383162813895037, 1]}, {'proactive_mlc_reward': [0.37853814454280926, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4201941832634538, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4999608380718019, 1]}, {'proactive_mlc_reward': [0.4646383033318338, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4353573570376336, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.47814068097414403, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49995938734680256, 1]}]}\n",
      "{'speed': 24.999931132145026, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.24518331729189866, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999311321450257, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.31121568003505284, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6670723093365403, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3162156800625761, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.22250985978090299, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3234188844155737, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.25000430228842613, 1]}, {'proactive_mlc_reward': [0.388669203567241, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999268256400276, 1]}, {'proactive_dlc_reward': [0.7226824782706818, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.44536495654136365, 1]}, {'proactive_mlc_reward': [0.3985380511235953, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.44519399163777557, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4999927756848727, 1]}, {'proactive_mlc_reward': [0.49463870146412753, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4553565582290686, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.5031404822498327, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999925080654005, 1]}]}\n",
      "{'speed': 23.024121066562607, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.09099894027027179, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.29579676663443133, 1]}, {'proactive_dlc_reward': [0.6782150756682414, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.35643015133648265, 1]}, {'proactive_mlc_reward': [0.1288881395625954, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5062161138562203, 1]}, {'proactive_dlc_reward': [0.6807498578696926, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36149971573938516, 1]}, {'proactive_mlc_reward': [0.16333258634327896, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.2965955195034155, 1]}, {'proactive_dlc_reward': [0.6799635060821366, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3599270121642732, 1]}, {'proactive_mlc_reward': [0.19848216128261803, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.11148608410943624, 1]}, {'proactive_dlc_reward': [0.7784430935313377, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.5546959481516238, 1]}, {'proactive_mlc_reward': [0.2379465434505445, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.31708701510893106, 1]}, {'proactive_dlc_reward': [0.6849596847240107, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3699193694480215, 1]}, {'proactive_mlc_reward': [0.27435064215274296, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12501828916804386, 1]}, {'proactive_mlc_reward': [0.29257665588716114, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3096915240860884, 1]}, {'proactive_mlc_reward': [0.31359830984414083, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5358555979437962, 1]}, {'proactive_mlc_reward': [0.32962308673212326, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10831637717142009, 1]}, {'proactive_mlc_reward': [0.348137642174603, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3125634050026761, 1]}]}\n",
      "{'speed': 24.63550384965481, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.11502348533596148, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46349254682215424, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26963348046599017, 1]}, {'proactive_mlc_reward': [0.1564719747685828, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9089102461916603, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.270568677798941, 1]}, {'proactive_mlc_reward': [0.18701287078708403, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45578228589648867, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2702785565829789, 1]}, {'proactive_mlc_reward': [0.2190276808084802, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.020566163132401272, 1]}, {'proactive_dlc_reward': [0.8571878658143085, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.714369890561462, 1]}, {'proactive_mlc_reward': [0.26207514241761254, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46742142780254986, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2721218758780859, 1]}, {'proactive_mlc_reward': [0.2949623769569191, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.023062488472013955, 1]}, {'proactive_mlc_reward': [0.3166454455896839, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.46489324033228774, 1]}, {'proactive_mlc_reward': [0.3413271758621387, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.914377928277499, 1]}, {'proactive_mlc_reward': [0.3501530963668655, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.019981438047742373, 1]}, {'proactive_mlc_reward': [0.3722204844571268, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46542302458203616, 1]}]}\n",
      "{'speed': 24.932760331937274, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.13984506374203173, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49327565610630836, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.049740074642656215, 1]}, {'proactive_mlc_reward': [0.18642231093503653, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04991259322256827, 1]}, {'proactive_mlc_reward': [0.21182351520200896, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49321628341243373, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04985907371559737, 1]}, {'proactive_mlc_reward': [0.2390258554430095, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.8717141436500757, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7434282859225295, 1]}, {'proactive_mlc_reward': [0.2869159550536155, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49400090912399686, 1]}, {'proactive_dlc_reward': [0.5284214988215968, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.05684299764319363, 1]}, {'proactive_mlc_reward': [0.3157170779142495, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3414736625098361, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4935237536402539, 1]}, {'proactive_mlc_reward': [0.371270296003036, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3701476748348346, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3970512936977021, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49362148448614535, 1]}]}\n",
      "{'speed': 23.12692714343816, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 4, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.09266798655074646, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3060652524664132, 1]}, {'proactive_dlc_reward': [0.6837244091500122, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36744881830002446, 1]}, {'proactive_mlc_reward': [0.13100475591230742, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5045104804412801, 1]}, {'proactive_dlc_reward': [0.6800016494253575, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36000329885071486, 1]}, {'proactive_mlc_reward': [0.16547978646666808, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.2932889093064105, 1]}, {'proactive_dlc_reward': [0.6828717998254307, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3657435996508614, 1]}, {'proactive_mlc_reward': [0.2022116802022847, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.1286374483046508, 1]}, {'proactive_dlc_reward': [0.677007540081179, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.35401508016235805, 1]}, {'proactive_mlc_reward': [0.2351947292808558, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.29631845930176903, 1]}, {'proactive_dlc_reward': [0.6815897547606223, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3631795095212446, 1]}, {'proactive_mlc_reward': [0.2755078645069909, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.11843918898135222, 1]}, {'proactive_mlc_reward': [0.2980313130614574, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3330460365567262, 1]}, {'proactive_mlc_reward': [0.31666007310911276, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5338393406124883, 1]}, {'proactive_mlc_reward': [0.33244740962280017, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10117760385579153, 1]}, {'proactive_mlc_reward': [0.3532543273597231, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3127396426781111, 1]}]}\n",
      "{'speed': 24.654468786533833, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.11639494831126976, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4575186355171919, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27166612610139806, 1]}, {'proactive_mlc_reward': [0.15858024517683267, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9085956030203999, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27029262941054916, 1]}, {'proactive_mlc_reward': [0.18914377540883454, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45517601522362233, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27135155944318967, 1]}, {'proactive_mlc_reward': [0.22284112414022395, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.023730125314765614, 1]}, {'proactive_dlc_reward': [0.7365348680051207, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4730697360102415, 1]}, {'proactive_mlc_reward': [0.2592218244335482, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46358884067030637, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2708785542577159, 1]}, {'proactive_mlc_reward': [0.29608740670486017, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.021848822669821643, 1]}, {'proactive_mlc_reward': [0.32221438018857096, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.46920151537114696, 1]}, {'proactive_mlc_reward': [0.3443790732523498, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.914005983406318, 1]}, {'proactive_mlc_reward': [0.3529424880796695, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.018664527710931012, 1]}, {'proactive_mlc_reward': [0.3770141954266529, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.458742494603824, 1]}]}\n",
      "{'speed': 24.936258849162673, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.1412141159570222, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4935385630762504, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.050115042712098656, 1]}, {'proactive_mlc_reward': [0.18852879739940906, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04986166977114852, 1]}, {'proactive_mlc_reward': [0.21395144341511296, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4931037348340627, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0500570136830909, 1]}, {'proactive_mlc_reward': [0.24281630288766393, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7475160478241019, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49503209564820383, 1]}, {'proactive_mlc_reward': [0.28404387426206296, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49329343178900975, 1]}, {'proactive_dlc_reward': [0.7288666492867303, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4577332985734605, 1]}, {'proactive_mlc_reward': [0.3160934699308967, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.34706367819857625, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4943185137035936, 1]}, {'proactive_mlc_reward': [0.37432006777873494, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3729289673074304, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.40183936965080863, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4937656713482905, 1]}]}\n",
      "{'speed': 24.988241483976775, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.16618281841487417, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49882350641972906, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2185472937409367, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.23891801651233496, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4987432083673792, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.26280281988163445, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7495417780966058, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49908355619321154, 1]}, {'proactive_mlc_reward': [0.3090110593480924, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4987628871512772, 1]}, {'proactive_dlc_reward': [0.8480423545336523, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6960847090673046, 1]}, {'proactive_mlc_reward': [0.33609302689799664, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3720358777628953, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4989519196504236, 1]}, {'proactive_mlc_reward': [0.40432992677921015, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.392921392968756, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.42680918425012326, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49886544509263403, 1]}]}\n",
      "{'speed': 24.99783087225047, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.19117706402671322, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997830830415559, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.24855404106410306, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.26391186919600435, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.499768269415522, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2827979013847093, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7499154704688811, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49983094093776226, 1]}, {'proactive_mlc_reward': [0.3340050059626313, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997717865999462, 1]}, {'proactive_dlc_reward': [0.9719679298915113, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9439358597830225, 1]}, {'proactive_mlc_reward': [0.3560928652830011, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3970307493354332, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49980665756074033, 1]}, {'proactive_mlc_reward': [0.4343335232667751, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.41291862990824846, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4518036350833852, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49979082001078334, 1]}]}\n",
      "{'speed': 24.99959985467686, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.2161760026324231, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49995998544160225, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.27855650243571234, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2889107353161128, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999572527229617, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.30279610715485034, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7499844065908281, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999688131816562, 1]}, {'proactive_mlc_reward': [0.35900388927743404, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49995790081094216, 1]}, {'proactive_dlc_reward': [1.0011877163124416, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3760928063270935, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.42202980327946016, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49996433355626485, 1]}, {'proactive_mlc_reward': [0.46433483523778435, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4329176219650213, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.476802611547406, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999614127059136, 1]}]}\n",
      "{'speed': 24.999926184025046, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.24117580683478432, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999261840234477, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.30855740032514933, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.31391052614683684, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999211428972784, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.32279545263359416, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7499971234383253, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999424687665056, 1]}, {'proactive_mlc_reward': [0.3840036832792613, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999223383980934, 1]}, {'proactive_dlc_reward': [1.000433269778135, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3960927848204317, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.44702962875775504, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49999342050708756, 1]}, {'proactive_mlc_reward': [0.49433531383472057, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4529172542750825, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.5018024227336039, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999288169397504, 1]}]}\n",
      "{'speed': 24.99998638295178, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.2661757707154281, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999863829517677, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3304899771943053, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.33552596986735167, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.34279521386927275, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7499994693522771, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999893870455414, 1]}, {'proactive_mlc_reward': [0.40900364527817734, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999985673537772, 1]}, {'proactive_dlc_reward': [1.000158053483546, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.41609277697496666, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.47202959656322724, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49999878626175087, 1]}, {'proactive_mlc_reward': [0.524335488423203, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4729171201446199, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.5268023879025766, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999986868653529, 1]}]}\n",
      "{'speed': 22.99117058034489, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 4, 0, 4, 0, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.09007536561417674, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.2925061341986229, 1]}, {'proactive_dlc_reward': [0.6786356527990345, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3572713055980691, 1]}, {'proactive_mlc_reward': [0.1297094055597115, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5190584355386388, 1]}, {'proactive_dlc_reward': [0.6801991198870474, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3603982397740948, 1]}, {'proactive_mlc_reward': [0.16538456890009795, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.2932244578948694, 1]}, {'proactive_dlc_reward': [0.6788734450382223, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.35774689007644456, 1]}, {'proactive_mlc_reward': [0.2029842130568423, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10849190895703167, 1]}, {'proactive_dlc_reward': [0.6832222145103409, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3664444290206818, 1]}, {'proactive_mlc_reward': [0.24316729378859842, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3220734327879466, 1]}, {'proactive_dlc_reward': [0.6845284974338592, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3690569948677185, 1]}, {'proactive_mlc_reward': [0.2785564418248681, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3120371321545921, 1]}, {'proactive_mlc_reward': [0.2951990115168616, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3061740548364071, 1]}, {'proactive_mlc_reward': [0.3167155871398524, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.517505276162818, 1]}, {'proactive_mlc_reward': [0.33420611390626087, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10834303102297867, 1]}, {'proactive_mlc_reward': [0.3539068697035134, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3060821242485954, 1]}]}\n",
      "{'speed': 24.62942537734808, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.11373549716310861, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45503249419510505, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26978865064620994, 1]}, {'proactive_mlc_reward': [0.15735608033254814, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9112793067325271, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2703654853146995, 1]}, {'proactive_mlc_reward': [0.18904824023218236, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4551641980981877, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26987638310218093, 1]}, {'proactive_mlc_reward': [0.22351508159713498, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.020013818908248382, 1]}, {'proactive_dlc_reward': [0.7376813071248179, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.47260020573025174, 1]}, {'proactive_mlc_reward': [0.2672966701824404, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46717736714763947, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27196279112377403, 1]}, {'proactive_mlc_reward': [0.30138364352549657, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26259660228516213, 1]}, {'proactive_mlc_reward': [0.31925058967076236, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.46424436251959944, 1]}, {'proactive_mlc_reward': [0.344354662051477, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9109927908920185, 1]}, {'proactive_mlc_reward': [0.35473625396262987, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.019986354961487506, 1]}, {'proactive_mlc_reward': [0.3779579980261096, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46422740381591154, 1]}]}\n",
      "{'speed': 24.931639018420395, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.13854246053963554, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.493077089901697, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04976869933842174, 1]}, {'proactive_mlc_reward': [0.18728149227141316, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04987510971230247, 1]}, {'proactive_mlc_reward': [0.21385585022165124, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49310154098677367, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.049784883600483984, 1]}, {'proactive_mlc_reward': [0.24350985921333745, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7477275347925912, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4954319624828855, 1]}, {'proactive_mlc_reward': [0.2921360637062672, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49394511317651146, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.050169769374126004, 1]}, {'proactive_mlc_reward': [0.32266883043716843, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.048454275019251015, 1]}, {'proactive_mlc_reward': [0.34407563152633547, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49340405325741726, 1]}, {'proactive_mlc_reward': [0.37427843659115795, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3747308626705203, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.40278295689998994, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4934009248358805, 1]}]}\n",
      "{'speed': 24.98738925032404, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.1635089031552531, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49873828790509583, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2152760067532863, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2546626955384568, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.23882241257549436, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49874280323452885, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2635053066450174, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7495807917145749, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4991614934552052, 1]}, {'proactive_mlc_reward': [0.3171064361611303, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49888303736601003, 1]}, {'proactive_dlc_reward': [0.606568367233156, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.21313673446631204, 1]}, {'proactive_mlc_reward': [0.34266840596627934, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.36904335648709286, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49878322646450285, 1]}, {'proactive_mlc_reward': [0.4042821338865551, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.39472624859602556, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4277506665528729, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4987826493554561, 1]}]}\n",
      "{'speed': 23.185096722783058, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 4, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.09387329839041363, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3118764031069077, 1]}, {'proactive_dlc_reward': [0.6770979128167116, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3541958256334231, 1]}, {'proactive_mlc_reward': [0.1336414809434114, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.506078294718668, 1]}, {'proactive_dlc_reward': [0.6796205843208121, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.35924116864162414, 1]}, {'proactive_mlc_reward': [0.1694235858996432, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.31160495642411307, 1]}, {'proactive_dlc_reward': [0.6781287412193164, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.356257482438633, 1]}, {'proactive_mlc_reward': [0.20630573892494464, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12207735869684058, 1]}, {'proactive_dlc_reward': [0.6766585588892694, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.35331711777853875, 1]}, {'proactive_mlc_reward': [0.24082566361376376, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.29348914363418255, 1]}, {'proactive_dlc_reward': [0.6838355841617414, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3676711683234828, 1]}, {'proactive_mlc_reward': [0.2776671717801503, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.1148261300340522, 1]}, {'proactive_mlc_reward': [0.29836787504373735, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.31716906867942674, 1]}, {'proactive_mlc_reward': [0.31732080884054703, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5188311087465649, 1]}, {'proactive_mlc_reward': [0.33117400621099424, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10044994584543723, 1]}, {'proactive_mlc_reward': [0.3516248175057216, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3271278743661359, 1]}]}\n",
      "{'speed': 24.665199498511985, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.11762891014929369, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45858420274332834, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26922130788618226, 1]}, {'proactive_mlc_reward': [0.16122464177796333, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9088848222933479, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2701520370278006, 1]}, {'proactive_mlc_reward': [0.19352539465721344, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4664099363210408, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2696016277307411, 1]}, {'proactive_mlc_reward': [0.22690308327842865, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.022519966449512197, 1]}, {'proactive_dlc_reward': [0.7364704904266965, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4729409808533932, 1]}, {'proactive_mlc_reward': [0.2644906392947062, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4552127280880988, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2717071436588043, 1]}, {'proactive_mlc_reward': [0.29822903469347406, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.021182311146784726, 1]}, {'proactive_mlc_reward': [0.3224732535870446, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4662726447948707, 1]}, {'proactive_mlc_reward': [0.34496637126644986, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9112373710960988, 1]}, {'proactive_mlc_reward': [0.3516655241189754, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.018530294515235468, 1]}, {'proactive_mlc_reward': [0.3757789261035446, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4681097747290039, 1]}]}\n",
      "{'speed': 24.938238374901992, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.14245330753721347, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49373629976903005, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04966403996458215, 1]}, {'proactive_mlc_reward': [0.1911748337976124, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04983573428420485, 1]}, {'proactive_mlc_reward': [0.21836125548436752, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4938141947931555, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04973419867567337, 1]}, {'proactive_mlc_reward': [0.2468708946818698, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7475041719044252, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49500834380885034, 1]}, {'proactive_mlc_reward': [0.2892984875442318, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4931105505448091, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.050122609340558455, 1]}, {'proactive_mlc_reward': [0.31823099875134736, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.34730822015738355, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4937782164050869, 1]}, {'proactive_mlc_reward': [0.3748915435488381, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3716511777879526, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4006228820491818, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49411711712280953, 1]}]}\n",
      "{'speed': 24.988606652864036, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.1674229783053257, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4988600212455882, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.22119391488349802, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2433309888177834, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.498858957171176, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2668547321192213, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7495395873110617, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49907917462212337, 1]}, {'proactive_mlc_reward': [0.31426509401832153, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49874446700914066, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3382290630497294, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.37227777595922346, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49885224943175893, 1]}, {'proactive_mlc_reward': [0.40489574098854336, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3916433028307815, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4255940961473044, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.498914767435706, 1]}]}\n",
      "{'speed': 24.99789823602027, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.1924174025977023, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997898194037109, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2512008755169099, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2683254055190368, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997895089404736, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2868488361406453, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7499150663282814, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49983013265656273, 1]}, {'proactive_mlc_reward': [0.33925895286099356, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997685016136021, 1]}, {'proactive_dlc_reward': [-1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.35822835692066324, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.39727215982918523, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49978827110477225, 1]}, {'proactive_mlc_reward': [0.43489727218227253, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4116404301069578, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4505887859280188, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997998039833206, 1]}]}\n",
      "{'speed': 24.99961228146797, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.21741637416558193, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999612281206172, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2812034147024565, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2933243755521344, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49996117010294583, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.30684668533299636, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.655625727160296, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.31125145432059204, 1]}, {'proactive_mlc_reward': [0.36425782011728675, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49995729555730967, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.37881785803029033, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4222711238052953, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4999609417530991, 1]}, {'proactive_mlc_reward': [0.4648978307499712, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.43163938215939596, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4755878063363777, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999630692568456, 1]}]}\n",
      "{'speed': 23.263444234386334, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 4, 1, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.09687526309040526, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.31970445470274883, 1]}, {'proactive_dlc_reward': [0.6785603753298217, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3571207506596433, 1]}, {'proactive_mlc_reward': [0.13427048708342998, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5282279309756781, 1]}, {'proactive_dlc_reward': [0.6771075196296517, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3542150392593033, 1]}, {'proactive_mlc_reward': [0.16884109552611326, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.3099253242355708, 1]}, {'proactive_dlc_reward': [0.6809354974995332, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3618709949990663, 1]}, {'proactive_mlc_reward': [0.20377356126984875, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12649545525258787, 1]}, {'proactive_dlc_reward': [0.6801247878898421, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.36024957577968414, 1]}, {'proactive_mlc_reward': [0.24193923069452677, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3155386869636114, 1]}, {'proactive_dlc_reward': [0.6800285133665434, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.3600570267330866, 1]}, {'proactive_mlc_reward': [0.2750030401731572, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.10539917698693024, 1]}, {'proactive_mlc_reward': [0.29664554684547284, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.32548353374151373, 1]}, {'proactive_mlc_reward': [0.31713655601502483, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.5174700411231019, 1]}, {'proactive_mlc_reward': [0.33335737000685783, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.12574477355575375, 1]}, {'proactive_mlc_reward': [0.3513229352178367, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.2961216013075852, 1]}]}\n",
      "{'speed': 24.67965249251139, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.1210166525652745, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46790433312902097, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26976087733756077, 1]}, {'proactive_mlc_reward': [0.16196202968746878, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9129708303025442, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.26922485227979304, 1]}, {'proactive_mlc_reward': [0.1929110292507598, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4649363701278414, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.27063716876696836, 1]}, {'proactive_mlc_reward': [0.2243925240877137, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.023334985608414627, 1]}, {'proactive_dlc_reward': [0.7371099158011681, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.47145701868451173, 1]}, {'proactive_mlc_reward': [0.26603663151516416, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46597188352405006, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2703025407497307, 1]}, {'proactive_mlc_reward': [0.29551877547335614, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.019443293620451385, 1]}, {'proactive_mlc_reward': [0.3207916094174167, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4678064384175588, 1]}, {'proactive_mlc_reward': [0.34477545851587443, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9109862909814634, 1]}, {'proactive_mlc_reward': [0.3539726596171958, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.023196505166115954, 1]}, {'proactive_mlc_reward': [0.37534906811089264, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46355250482444993, 1]}]}\n",
      "{'speed': 24.940904560863387, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 4, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.145859829277779, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49409004957632197, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04976357591516241, 1]}, {'proactive_mlc_reward': [0.19189710845420727, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04966469380921055, 1]}, {'proactive_mlc_reward': [0.21773945721201016, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4935317099194446, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04992522795122341, 1]}, {'proactive_mlc_reward': [0.24436529725830944, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7476221285684108, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4919628513955182, 1]}, {'proactive_mlc_reward': [0.2908701264117314, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4937227340961609, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.04986349814479816, 1]}, {'proactive_mlc_reward': [0.3155100442543544, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.34563408108919, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4940611597886278, 1]}, {'proactive_mlc_reward': [0.37469919590944784, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.37394458973066524, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.40017094005130865, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49328672425464004, 1]}]}\n",
      "{'speed': 24.989098491965407, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.17083091244980408, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4989098466625787, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.22190485066058246, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2427078068175589, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.498806775661312, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.264350939326478, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7495613471209381, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4990952260001569, 1]}, {'proactive_mlc_reward': [0.315839410729618, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4988420144483946, 1]}, {'proactive_dlc_reward': [0.6065401178596337, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.2130802357192673, 1]}, {'proactive_mlc_reward': [0.3355042139808181, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.37060502137898366, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4989044448230466, 1]}, {'proactive_mlc_reward': [0.404702879913118, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.3939299251728228, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4251380923153821, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4987616497493807, 1]}]}\n",
      "{'speed': 24.997988967013953, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.19582557816186977, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49979889668589833, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2519076749579363, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.26770196817697256, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49977988242569465, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2843457016633476, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7499190804238811, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49983805213426746, 1]}, {'proactive_mlc_reward': [0.34083374451814336, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49978638302753603, 1]}, {'proactive_dlc_reward': [0.7235355370796075, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.447071074159215, 1]}, {'proactive_mlc_reward': [0.35550208714186243, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3955996606494768, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4997978997408531, 1]}, {'proactive_mlc_reward': [0.4347042238093296, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4139245756548812, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.45013203287510567, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49977155833250214, 1]}]}\n",
      "{'speed': 24.999629018879038, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.22082459413073308, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999629018878096, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.28190870523989453, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.2927008911059128, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999593942690016, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3043437910041114, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7499850725297568, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999701448045963, 1]}, {'proactive_mlc_reward': [0.36583269925558465, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49996059345398436, 1]}, {'proactive_dlc_reward': [0.847058908714341, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6941178174286818, 1]}, {'proactive_mlc_reward': [0.37550131128736525, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.420598671740068, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4999627179756839, 1]}, {'proactive_mlc_reward': [0.464704714052334, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.43392262419187, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.47513091507295846, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49995785870177833, 1]}]}\n",
      "{'speed': 24.99993156403049, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.24582441260364216, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999931564030483, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.31190908107883086, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3177006924154726, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999250934235884, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.32434309401031347, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.749997246286022, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999449257174133, 1]}, {'proactive_mlc_reward': [0.39083250643295164, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999273055951077, 1]}, {'proactive_dlc_reward': [0.9717865107725834, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.9435730215451666, 1]}, {'proactive_mlc_reward': [0.39550102826161027, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4455984893130648, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4999931224762257, 1]}, {'proactive_mlc_reward': [0.49470489288921243, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.4539219123131688, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.5001307088687389, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999222607180976, 1]}]}\n",
      "{'speed': 24.999987375417085, 'crashed': False, 'action': array([0, 4, 3, 4, 0, 4, 4, 2, 0, 3, 4, 1, 3, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.2708243791168103, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999987375417085, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.33470123087296366, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.3397324793495562, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [1, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.34434283975233515, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_dlc_reward': [0.7499994920143502, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999989840287006, 1]}, {'proactive_mlc_reward': [0.415832470862398, 2], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999865898510903, 1]}, {'proactive_dlc_reward': [1.0011272870925827, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [1.0, 1]}, {'proactive_mlc_reward': [0.415500925015991, 2], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4691910391663439, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.5168016241324654, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.4742142052892849, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.5218367834822241, 2], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "###MODEL TESTING###\n",
    "model = PPO.load('Training/Saved Models/A2C_model', env=env)\n",
    "for episode in trange(10, desc=\"Test episodes\"):\n",
    "    obs, done = env.reset(), False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        print(info)\n",
    "        env.render('human')\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('HighwayEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3ad5ee2ef26874e04e7cedb1b85599df4bcd7c0a1b3970111d4d655b242d185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
