{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:32: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 5)\u001b[0m\n",
      "  \"A Box observation space has an unconventional shape (neither an image, nor a 1D vector). \"\n",
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 1.        ,  1.        ,  0.6666667 ,  0.3125    ,  0.        ],\n",
      "       [ 1.        ,  0.10451003, -0.33333334, -0.02887931,  0.        ],\n",
      "       [ 1.        ,  0.23779099, -0.6666667 , -0.03699712,  0.        ],\n",
      "       [ 1.        ,  0.36057743,  0.        , -0.05333721,  0.        ],\n",
      "       [ 1.        ,  0.48616242, -0.6666667 , -0.02385702,  0.        ]],\n",
      "      dtype=float32), 4.0, False, {'speed': 25.0, 'crashed': False, 'action': 1, 'rewards': {'~collision_penalty': 1, '~lane change penalty': 0, '~sudden aceleration penalty': 0, '~target speed reward': 1, '~target lane reward': 1, 'on_road_reward': 1.0}})\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import highway_env\n",
    "import matplotlib.pyplot as plt \n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "env = gym.make('ma-highway-v0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation space: Box(-inf, inf, (5, 5), float32)\n",
      "The action space: Discrete(5)\n"
     ]
    }
   ],
   "source": [
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "print(\"The observation space: {}\".format(obs_space))\n",
    "print(\"The action space: {}\".format(action_space))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-0.24781735, -0.89376765,  0.5502368 ,  0.386194  , -0.23347892],\n",
      "       [-1.1975341 , -0.8934713 , -1.0350403 , -0.30027187,  0.33148178],\n",
      "       [-0.0183775 ,  2.9464455 , -0.7097694 , -1.6262903 ,  0.78689456],\n",
      "       [-1.5658585 ,  0.4565787 ,  0.20267242, -0.88431674, -2.4059784 ],\n",
      "       [-0.82652104,  0.69788367,  0.47182578,  0.19536518, -0.35112184]],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "\n",
    "pp(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n",
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa2dc1c408>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "env_screen = env.render(mode = 'rgb_array')\n",
    "env.close()\n",
    "plt.imshow(env_screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.configure({'simulation_frequency':20, 'show_trajectories':False, 'initial_lane_id':1, 'duration':10, 'vehicles_density':1, 'ego_spacing':1})\n",
    "\n",
    "\n",
    "for trials in range(10):\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        while not done:\n",
    "            # Predict\n",
    "            random_action = env.action_space.sample()\n",
    "            # Get reward\n",
    "            obs, reward, done, info = env.step(random_action)\n",
    "            # Render\n",
    "            env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4969254e-01,\n",
      "         4.8077764e-11],\n",
      "       [ 1.0000000e+00,  9.7593823e-03, -3.3333334e-01,  5.8310926e-03,\n",
      "        -5.4176885e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.6314361e-10, -2.4297187e-01,\n",
      "        -4.8077764e-11],\n",
      "       [ 1.0000000e+00,  3.6027530e-01, -5.7516780e-10, -2.2051435e-02,\n",
      "        -4.8077764e-11],\n",
      "       [ 1.0000000e+00,  4.3860507e-01, -6.6666669e-01,  3.3753812e-02,\n",
      "        -4.8077764e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.975403806219123}]\n",
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4988978e-01,\n",
      "         4.8115734e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.6870916e-10, -2.4748051e-01,\n",
      "        -4.8115623e-11],\n",
      "       [ 1.0000000e+00,  6.1152969e-02, -3.3333334e-01,  5.6622946e-03,\n",
      "        -4.8736792e-11],\n",
      "       [ 1.0000000e+00,  4.0087181e-01, -7.3828044e-10, -2.0388596e-02,\n",
      "        -4.8115623e-11],\n",
      "       [ 1.0000000e+00,  4.9375743e-01, -3.3333334e-01,  6.4193197e-03,\n",
      "        -4.8146376e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.991182610784723}]\n",
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4996048e-01,\n",
      "         4.8129278e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.7072443e-10, -2.4909680e-01,\n",
      "        -4.8129278e-11],\n",
      "       [ 1.0000000e+00,  1.1307780e-01, -3.3333334e-01,  5.5803549e-03,\n",
      "        -4.8192561e-11],\n",
      "       [ 1.0000000e+00,  4.4268900e-01, -8.9969932e-10, -1.8860294e-02,\n",
      "        -4.8129278e-11],\n",
      "       [ 1.0000000e+00,  5.4588121e-01, -3.3333334e-01,  5.7926350e-03,\n",
      "        -4.8132498e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.996839090093925}]\n",
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4998583e-01,\n",
      "         4.8134385e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.7146717e-10, -2.4967621e-01,\n",
      "        -4.8134274e-11],\n",
      "       [ 1.0000000e+00,  1.6372325e-01, -5.8479249e-01,  4.2877598e-03,\n",
      "        -3.1434048e-02],\n",
      "       [ 1.0000000e+00,  4.8529261e-01, -1.0605107e-09, -1.7502649e-02,\n",
      "        -4.8134274e-11],\n",
      "       [ 1.0000000e+00,  5.9796816e-01, -3.3333334e-01,  5.1937220e-03,\n",
      "        -4.8134496e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.998866858296672}]\n",
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4999492e-01,\n",
      "         4.8135940e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.7175361e-10, -2.4988393e-01,\n",
      "        -4.8135940e-11],\n",
      "       [ 1.0000000e+00,  2.1643150e-01, -6.5779895e-01,  8.0877161e-03,\n",
      "        -3.8617691e-03],\n",
      "       [ 1.0000000e+00,  5.2848232e-01, -1.2211044e-09, -1.6306665e-02,\n",
      "        -4.8135940e-11],\n",
      "       [ 1.0000000e+00,  6.4989173e-01, -3.3333334e-01,  4.6032099e-03,\n",
      "        -4.8136051e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.999593784651264}]\n",
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4999818e-01,\n",
      "         4.8136606e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.7187707e-10, -2.4995840e-01,\n",
      "        -4.8136606e-11],\n",
      "       [ 1.0000000e+00,  2.6990622e-01, -6.6577280e-01,  9.3053617e-03,\n",
      "        -3.9550554e-04],\n",
      "       [ 1.0000000e+00,  5.7214957e-01, -1.3816206e-09, -1.5251477e-02,\n",
      "        -4.8136606e-11],\n",
      "       [ 1.0000000e+00,  7.0160675e-01, -3.3333334e-01,  4.0182015e-03,\n",
      "        -4.8136606e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.999854377516012}]\n",
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4999934e-01,\n",
      "         4.8136828e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.7194102e-10, -2.4998508e-01,\n",
      "        -4.8136828e-11],\n",
      "       [ 1.0000000e+00,  3.2377738e-01, -6.6657776e-01,  1.0060628e-02,\n",
      "        -3.9452818e-05],\n",
      "       [ 1.0000000e+00,  6.1622506e-01, -1.5421079e-09, -1.4315509e-02,\n",
      "        -4.8136828e-11],\n",
      "       [ 1.0000000e+00,  7.5309873e-01, -3.3333334e-01,  3.4408618e-03,\n",
      "        -4.8136939e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.999947796389506}]\n",
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4999976e-01,\n",
      "         4.8137050e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.7198520e-10, -2.4999465e-01,\n",
      "        -4.8136939e-11],\n",
      "       [ 1.0000000e+00,  3.7790143e-01, -6.6665787e-01,  1.0562548e-02,\n",
      "        -3.9107836e-06],\n",
      "       [ 1.0000000e+00,  6.6065878e-01, -1.7025866e-09, -1.3479778e-02,\n",
      "        -4.8136939e-11],\n",
      "       [ 1.0000000e+00,  8.0436510e-01, -3.3333334e-01,  2.8745448e-03,\n",
      "        -4.8136939e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.999981285740535}]\n",
      "[array([[ 1.00000000e+00,  1.00000000e+00,  6.66666687e-01,\n",
      "         2.49999911e-01,  4.81370499e-11],\n",
      "       [ 1.00000000e+00,  2.50000004e-02, -1.72022840e-10,\n",
      "        -2.49998078e-01, -4.81369389e-11],\n",
      "       [ 1.00000000e+00,  4.32196438e-01, -6.66665792e-01,\n",
      "         1.09143825e-02, -3.86641204e-07],\n",
      "       [ 1.00000000e+00,  7.05411553e-01, -1.86306215e-09,\n",
      "        -1.27284611e-02, -4.81369389e-11],\n",
      "       [ 1.00000000e+00,  8.55408847e-01, -3.33333343e-01,\n",
      "         2.32254597e-03, -4.81369389e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.999993291201438}]\n",
      "[array([[ 1.0000000e+00,  1.0000000e+00,  6.6666669e-01,  2.4999997e-01,\n",
      "         4.8137050e-11],\n",
      "       [ 1.0000000e+00,  2.5000000e-02, -1.7205537e-10, -2.4999931e-01,\n",
      "        -4.8136939e-11],\n",
      "       [ 1.0000000e+00,  4.8661372e-01, -6.6666657e-01,  1.1174180e-02,\n",
      "        -3.8198142e-08],\n",
      "       [ 1.0000000e+00,  7.5045127e-01, -2.0235356e-09, -1.2048626e-02,\n",
      "        -4.8136939e-11],\n",
      "       [ 1.0000000e+00,  9.0623540e-01, -3.3333334e-01,  1.7877482e-03,\n",
      "        -4.8136939e-11]], dtype=float32),\n",
      " 1.0,\n",
      " True,\n",
      " {'TimeLimit.truncated': False,\n",
      "  'action': 1,\n",
      "  'crashed': True,\n",
      "  'rewards': {'on_road_reward': 1.0,\n",
      "              '~collision_penalty': -1,\n",
      "              '~lane change penalty': 0,\n",
      "              '~sudden aceleration penalty': 0,\n",
      "              '~target lane reward': 1,\n",
      "              '~target speed reward': 0},\n",
      "  'speed': 19.999997594990155}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, info = env.step(action)\n",
    "    pprint([obs, reward, terminated, info])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:5: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  tensorboard.__version__\n",
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:32: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 5)\u001b[0m\n",
      "  \"A Box observation space has an unconventional shape (neither an image, nor a 1D vector). \"\n",
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "c:\\ProgramData\\Anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
     ]
    }
   ],
   "source": [
    "TRAIN = True\n",
    "\n",
    "# Create the model\n",
    "model = DQN('MlpPolicy', env,\n",
    "            policy_kwargs=dict(net_arch=[256, 256]),\n",
    "            learning_rate=5e-4,\n",
    "            buffer_size=15000,\n",
    "            learning_starts=200,\n",
    "            batch_size=32,\n",
    "            gamma=0.8,\n",
    "            train_freq=1,\n",
    "            gradient_steps=1,\n",
    "            target_update_interval=50,\n",
    "            verbose=1,\n",
    "            tensorboard_log=\"highway_dqn/\")\n",
    "\n",
    "# Train the model\n",
    "if TRAIN:\n",
    "    model.learn(total_timesteps=int(2e4))\n",
    "    model.save(\"highway_dqn/model\")\n",
    "    #del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('HighwayEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4299a72b06457e31910ea8504700d47f8bc36cfd064168ad296e1182d4a1645a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
