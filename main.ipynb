{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:32: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 4)\u001b[0m\n",
      "  \"A Box observation space has an unconventional shape (neither an image, nor a 1D vector). \"\n",
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import highway_env\n",
    "import matplotlib.pyplot as plt \n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "\n",
    "env = gym.make('ma-highway-v0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n",
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.configure(  {\n",
    "                \"speed_limit\": 20,\n",
    "                \"vehicles_density\": 1,\n",
    "                \"ego_spacing\": 1.25,\n",
    "                \"road_length\":10000, \n",
    "                 \"screen_width\": 2000, \n",
    "                \"simulation_frequency\":15, \n",
    "                \"duration\":40,\n",
    "                \"normalize_reward\": True,\n",
    "                \"DLC_config\": {\n",
    "                    \"count\": 3,\n",
    "                    \"reward_speed_range\": [23, 31],\n",
    "                    \"weights\": [2,10,1,1],\n",
    "                        },\n",
    "                \"MLC_config\": {\n",
    "                    \"count\":5 ,\n",
    "                    \"reward_speed_range\": [19, 23],\n",
    "                    \"weights\": [2,10,1,1]\n",
    "                        }, \n",
    "                })\n",
    "env.reset()\n",
    "plt.imshow(env.render(mode=\"rgb_array\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Visualization utils\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 42928), started 4 days, 23:43:17 ago. (Use '!kill 42928' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-35a42c977f75abda\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-35a42c977f75abda\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"highway_a2c/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to highway_a2c/2\\A2C_8\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.67     |\n",
      "|    ep_rew_mean        | 4.79     |\n",
      "| time/                 |          |\n",
      "|    fps                | 6        |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -11.5    |\n",
      "|    explained_variance | 0.562    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.16    |\n",
      "|    value_loss         | 0.202    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.86     |\n",
      "|    ep_rew_mean        | 4.96     |\n",
      "| time/                 |          |\n",
      "|    fps                | 6        |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.1    |\n",
      "|    explained_variance | 0.272    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.114   |\n",
      "|    value_loss         | 1.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.81     |\n",
      "|    ep_rew_mean        | 5.69     |\n",
      "| time/                 |          |\n",
      "|    fps                | 6        |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.2    |\n",
      "|    explained_variance | 0.368    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.329   |\n",
      "|    value_loss         | 0.318    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_428\\1830650739.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             normalize_advantage=True)\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mnew_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \"\"\"\n\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             )\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\stable_baselines3\\common\\monitor.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mstep_returns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_step_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstep_to_new_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_returns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\wrappers\\env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\Documents\\MasterThesis\\MasterThesisProject\\highway_env\\envs\\highway_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\Documents\\MasterThesis\\MasterThesisProject\\highway_env\\envs\\common\\abstract.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mterminated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_terminated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\Documents\\MasterThesis\\MasterThesisProject\\highway_env\\envs\\common\\observation.py\u001b[0m in \u001b[0;36mobserve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents_observation_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m             \u001b[0mspaces_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mspaces_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\Documents\\MasterThesis\\MasterThesisProject\\highway_env\\envs\\common\\observation.py\u001b[0m in \u001b[0;36mobserve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m                                                          \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvehicles_count\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                                                          \u001b[0msee_behind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msee_behind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                                          sort=self.order == \"sorted\")\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclose_vehicles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[0morigin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserver_vehicle\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\Documents\\MasterThesis\\MasterThesisProject\\highway_env\\road\\road.py\u001b[0m in \u001b[0;36mclose_vehicles_to\u001b[1;34m(self, vehicle, distance, count, see_behind, sort)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mvehicles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlane_distance_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[0mvehicles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvehicles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\Documents\\MasterThesis\\MasterThesisProject\\highway_env\\road\\road.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mvehicles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlane_distance_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[0mvehicles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvehicles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\Documents\\MasterThesis\\MasterThesisProject\\highway_env\\vehicle\\objects.py\u001b[0m in \u001b[0;36mlane_distance_to\u001b[1;34m(self, other, lane)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlane\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mlane\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlane\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\IoTLab\\Documents\\MasterThesis\\MasterThesisProject\\highway_env\\road\\lane.py\u001b[0m in \u001b[0;36mlocal_coordinates\u001b[1;34m(self, position)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlocal_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposition\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mlongitudinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[0mlateral\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection_lateral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlongitudinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlateral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "#MODEL TRAINING\n",
    "A2C_path = os.path.join('Training', 'Saved Models', 'A2C_model')\n",
    "\n",
    "model = A2C('MultiInputPolicy', env,\n",
    "            policy_kwargs=dict(net_arch=[256, 256]),\n",
    "            learning_rate=5e-4,\n",
    "            gamma=0.8,\n",
    "            verbose=1,\n",
    "            tensorboard_log=\"highway_a2c/2\",\n",
    "            normalize_advantage=True)\n",
    "\n",
    "model.learn(total_timesteps=int(1e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL SAVING\n",
    "model.save(A2C_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401b22ce545e4313bef185a06c2b000a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vehicles_speed': [20.895258694252718, 22.91393073683578, 20.701839446534482, 22.831219142396183, 20.78806332242364, 22.923698788446963, 20.902043478681854, 24.878706995697556, 18.82198285397846, 20.67448266481244], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.011265777523922563, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4738146735631794, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.01548039978435695, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4254598616336205, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.979478257928188, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.44701583060590977, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9748818572057012, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45997997134379975, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.22898297602855466, 1]}, {'proactive_mlc_reward': [-0.02943299617874809, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9684062943522356, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4186206662031102, 1]}], 'average_reward': 0.7226271379335996}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IoTLab\\anaconda3\\envs\\HighwayEnv\\lib\\site-packages\\gym\\core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vehicles_speed': [21.81121270854227, 22.156180010188436, 21.778159634756985, 22.142045571831535, 21.792894280690305, 22.157849255284006, 21.812372148375683, 26.637495983369973, 17.311355433435477, 21.773484682623454], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.013410820283065195, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7028031771355678, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.0176158205730636, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6945399086892463, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.977338547785684, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6982235701725763, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9727373326456705, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7029593353250316, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.44746447683357715, 1]}, {'proactive_mlc_reward': [-0.03122363382398066, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9662722344733042, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6933711706558636, 1]}], 'average_reward': 0.7785912889960828}\n",
      "{'vehicles_speed': [21.96773847304294, 19.95390991279034, 21.9620900916148, 19.951494503572107, 21.96460806924619, 19.954195167137883, 21.967936607669227, 19.043568440203764, 16.99961273931861, 21.96129119729774], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.015601428737195153, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7419346182607347, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.019804784745652133, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7405225229037002, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9751488506129974, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7411520173115473, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.970546673499401, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7419831564726449, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.033042670455777544, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9640835028641848, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.740322799324435, 1]}], 'average_reward': 0.6519327529491746}\n",
      "{'vehicles_speed': [20.96785934403441, 22.728367275544144, 20.86993587046213, 22.745359726836735, 20.884787763807953, 22.891785535841098, 20.748622992747368, 24.99151357124326, 18.857244512166883, 20.737484023567486], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.011417377096253036, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4919648360086022, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.015868575938730207, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45197469990605654, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02015382254932861, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4711969409519883, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024744550773292164, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.437155748186842, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.24893919640540751, 1]}, {'proactive_mlc_reward': [-0.02928581935295585, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9684844015200655, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4343710058918715, 1]}], 'average_reward': 0.6981446129179657}\n",
      "{'vehicles_speed': [21.823619305416173, 22.12446939787719, 21.806885335888946, 22.127373207880552, 21.809423349723673, 22.15239565588501, 21.786154392378858, 26.6567732999192, 17.317381235953285, 21.78425087360015], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.013566031498570134, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7059048263540433, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.018011507276547493, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7015885180276138, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.022298344414173672, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7023558374309182, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026882298889314284, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6965385980947145, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4570966624899002, 1]}, {'proactive_mlc_reward': [-0.031078211149528665, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9663472075310675, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6960627184000376, 1]}], 'average_reward': 0.753723901228466}\n",
      "{'vehicles_speed': [21.969858614480437, 19.948490942233562, 21.966998975969645, 19.948987169198727, 21.967432692673317, 19.95326321116423, 21.96345630163107, 26.941346595146637, 16.88828707515016, 21.9631310126674], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.01575725714002628, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7424646536201092, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.020201893523941493, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.741748756622143, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024488863853596696, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7418581731683291, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.029071660774759152, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7408640754077673, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49266832439332964, 1]}, {'proactive_mlc_reward': [-0.03276413514288739, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9641579403394115, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.74078275316685, 1]}], 'average_reward': 0.755031700382119}\n",
      "{'vehicles_speed': [21.99484919183938, 17.50386241192946, 21.994360513262603, 17.50394721127951, 21.99443463034442, 17.50467793654218, 21.993755111899024, 26.989976823189796, 16.960312378524016, 21.99369952384228], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.01795575770538474, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7487122979598446, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.022400251780057237, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7485901209970267, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026687243737336427, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7486086575861046, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03126984284614308, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7484387779747559, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4987471028987245, 1]}, {'proactive_mlc_reward': [-0.034456932612550006, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9619597744500821, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7484248809605702, 1]}], 'average_reward': 0.755090601267491}\n",
      "{'vehicles_speed': [21.999119787486535, 16.948377884081015, 21.99903627806725, 16.94840520942103, 21.99904894380452, 16.94864067486096, 21.99893282209699, 26.99828715700956, 16.98590040229867, 21.998923322752105], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.020155501469645915, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497799468716337, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024599971233785423, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497590694624119, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.028886966878528823, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497622359511302, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03346953218353121, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497332055242474, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49978589462619505, 1]}, {'proactive_mlc_reward': [-0.03615437381017254, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9597600878780166, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497308306880264, 1]}], 'average_reward': 0.7549361596179971}\n",
      "{'vehicles_speed': [21.999849582037477, 16.981660501690957, 21.99983531126024, 16.981670209410563, 21.999837475685723, 16.981753861890915, 21.999817631852125, 26.999707295285173, 16.994990915354816, 21.999816008525844], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.022355457681972855, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499623955093693, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026799923291790997, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499588278146554, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.031086919566615943, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499593689214308, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03566947909494591, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499544079630311, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49996341191064664, 1]}, {'proactive_mlc_reward': [-0.03785346475886692, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.957560141439163, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.749954002131461, 1]}], 'average_reward': 0.754745247855394}\n",
      "{'vehicles_speed': [21.99997429533993, 16.993484629751418, 21.999971856631998, 16.993488078558272, 21.99997222650685, 16.99351779730371, 21.999968835429158, 26.99994998020802, 16.99822045071681, 21.99996855802179], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.02455545019917471, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499935738349821, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02899991509906867, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499929641579968, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03328691148156667, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499930566267121, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.0378694700227313, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499922088572895, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999374752600234, 1]}, {'proactive_mlc_reward': [-0.03955314180533072, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9553601505921328, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499921395054479, 1]}], 'average_reward': 0.7545480990341817}\n",
      "{'vehicles_speed': [21.99999560737602, 16.997685321116162, 21.999995190629523, 16.997686546354345, 16.83572777479958, 16.99769710436561, 21.999994674341504, 26.99999145220605, 16.999367789551265, 21.999994626935845], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.026755448920452545, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499989018440054, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.031199913699028817, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499987976573808, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.0350641254747157, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.04006946847239656, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499986685853761, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999893152575625, 1]}, {'proactive_mlc_reward': [-0.041253027071447256, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9531601521562676, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499986567339612, 1]}], 'average_reward': 0.6246689961102627}\n",
      "{'vehicles_speed': [20.819055128211996, 22.744644585604878, 20.676031513473866, 22.88138939477844, 20.967657690471277, 22.897600600355045, 20.698321345669516, 25.033606776255258, 18.769028473870236, 20.84972426288315], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.011071227595169158, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.45476378205299905, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.015682669427236735, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.41900787836846654, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9794738547616907, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.49191442261781937, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9750586397895323, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4092021009660378, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.24825831428073464, 1]}, {'proactive_mlc_reward': [0.9705240446229103, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9680446227037618, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.44693585706822603, 1]}], 'average_reward': 0.7383496907343313}\n",
      "{'vehicles_speed': [21.798190415669357, 22.127250998657935, 21.773749362636906, 22.15061907769189, 21.823584845194762, 22.15338938199404, 21.777558432710933, 26.663966533413454, 17.302306152903057, 21.803431409950818], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.013212479477921715, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6995476039173392, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.017816806356286952, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6934373406592265, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9773252103909741, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7058962112986906, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9729242232653411, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6942616563187638, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45074513586651443, 1]}, {'proactive_mlc_reward': [0.9687360412836523, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.965902694265801, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7007255979333129, 1]}], 'average_reward': 0.7942453797151422}\n",
      "{'vehicles_speed': [21.965513116403102, 19.94896628508042, 21.96133642799798, 19.952959614853135, 21.969852725634038, 19.95343302726471, 21.9619873532585, 26.942575834119722, 16.99655094225616, 21.966408740663546], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.015402440115877688, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7413782791007755, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.020005551132365285, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7403341069994953, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9751339864638005, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7424631814085094, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9707352956511067, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7404958948396585, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49277922847076816, 1]}, {'proactive_mlc_reward': [0.9670345871232672, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9637124798069578, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7416012028998304, 1]}], 'average_reward': 0.7956379549263204}\n",
      "{'vehicles_speed': [21.99410659734437, 17.5039436424294, 21.993392850436233, 17.50462605550454, 21.994848185504807, 17.5047069561158, 21.993504085904874, 26.990186885667843, 16.99877467268563, 21.994259648993122], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.01760072450702121, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7485266493360925, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.022203627747018992, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7483482126090584, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9729354861913927, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7487120463762018, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9685371867043651, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7483760144968574, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49877321175643496, 1]}, {'proactive_mlc_reward': [0.9653348094963101, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9615141509128312, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.748564904969176, 1]}], 'average_reward': 0.7957037140135685}\n",
      "{'vehicles_speed': [21.99899288682424, 16.94840405941171, 21.998870915875138, 16.948623956961672, 21.999119615515795, 16.948650025990613, 21.998889924708, 26.998323054215593, 16.999564684867913, 21.9990190415503], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.01980043132965242, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.74974822170606, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02440329906309266, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497177289687844, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9707357424771934, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497799038789488, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.966337509855059, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497224811251435, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997903813607607, 1]}, {'proactive_mlc_reward': [0.9636348884975283, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9593144364767661, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497547603334711, 1]}], 'average_reward': 0.7955503787166105}\n",
      "{'vehicles_speed': [21.999827896207325, 16.981669800853233, 21.999807052807157, 16.98174792261701, 21.999849552649703, 16.981757184014064, 21.99981030119305, 26.999713429695337, 16.999845348045373, 21.999832365742286], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.02200038122908943, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499569740518313, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026603242894876734, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499517632017891, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9685357862734214, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499623881624258, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9641375650776508, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499525752978773, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49996417871089127, 1]}, {'proactive_mlc_reward': [0.9619349165638461, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9571144852762205, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499580914351691, 1]}], 'average_reward': 0.7953596487095494}\n",
      "{'vehicles_speed': [21.9999705894867, 16.99348793341241, 21.99996702759484, 16.993515687291328, 21.999974290317905, 16.99351897753569, 21.99996758270577, 26.999951028506544, 16.99994505767131, 21.99997135327764], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.024200372667492673, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499926473716751, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.028803233296389487, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499917568987096, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9663357937576815, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499935725794762, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9619375745145415, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499918956764402, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999938785633158, 1]}, {'proactive_mlc_reward': [0.9602349265348087, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9549144936154725, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499928383194074, 1]}], 'average_reward': 0.7951625284097223}\n",
      "{'vehicles_speed': [21.999994974089308, 16.997686494789193, 16.733746479280647, 16.997696354753405, 16.83572843983226, 16.99769752365998, 21.999994460265818, 26.999991631347935, 16.999980480948402, 21.99999510461219], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.026400371204416514, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749998743522327, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.030822510306630507, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.0, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9645496638074639, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9597375761271952, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499986150664544, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999989539184919, 1]}, {'proactive_mlc_reward': [0.9585349300771364, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9527144950405526, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499987761530473, 1]}], 'average_reward': 0.5355986221719597}\n",
      "{'vehicles_speed': [20.884089337700686, 22.950650196915515, 20.688678667995745, 22.950640967162915, 20.737400227589497, 22.722415207912285, 20.90974563657666, 24.91665621117012, 18.856159836375905, 20.8887679242478], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.988465077395912, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4710223344251716, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.015986508228060102, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4221696669989363, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9793092487255329, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.43435005689737416, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.025406501886184707, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46190044779666994, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.23958202639626514, 1]}, {'proactive_mlc_reward': [-0.03019132816556839, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03264374014585612, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45666992304080534, 1]}], 'average_reward': 0.7071535004674666}\n",
      "{'vehicles_speed': [21.809303996919184, 22.162454933897884, 21.77591061254619, 22.16245335664176, 21.784236553853404, 22.123452259547207, 21.81368835654114, 26.643981057807526, 17.317195877622225, 21.810103512314768], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9863205902754651, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7023259992297959, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.018121274311387076, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6939776531365478, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9771720589051088, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.696059138463351, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9724889689065954, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6844907728573384, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45549763222594075, 1]}, {'proactive_mlc_reward': [-0.0319836660030936, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9652527861448256, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6836019554444395, 1]}], 'average_reward': 0.7940236050696949}\n",
      "{'vehicles_speed': [21.96741229668326, 19.954982223425468, 21.961705760179566, 19.954981953890954, 21.96312856559116, 19.94831712525998, 21.96816153215902, 26.93916055147526, 16.888227346161447, 21.967548924457766], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.984130076773451, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7418530741708151, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.020310126602529073, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7404264400448914, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9749827924258131, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7407821413977898, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9702993589177965, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7418583838516444, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49239506893440765, 1]}, {'proactive_mlc_reward': [-0.03366957898961273, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9630633537169897, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7417053892862526, 1]}], 'average_reward': 0.7955953761768161}\n",
      "{'vehicles_speed': [21.994431144909683, 17.504971695512808, 21.993455964960738, 17.50497164945253, 21.99369910566574, 17.503832708653693, 21.994559180437452, 26.989603254045978, 16.960291158942677, 21.99445449298887], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9819316979043445, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7486077862274207, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.022508221590242204, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7483639912401845, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9727846266582175, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7484247764164351, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9681009524792726, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7486383906987184, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4987004067557472, 1]}, {'proactive_mlc_reward': [-0.0353623726083346, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9608649777445131, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7486122202529577, 1]}], 'average_reward': 0.7956617295191306}\n",
      "{'vehicles_speed': [21.99904834818473, 16.948735334357202, 21.998881701404812, 16.948735319514952, 21.998923251290652, 16.94836831263843, 21.99907022795004, 26.99822331843806, 16.985892863737558, 21.99905233809676], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9797319749365411, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497620870461823, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02470789604605556, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497204253512031, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9705849401069551, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749730812822663, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9659012232159561, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497675464775799, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49977791480475764, 1]}, {'proactive_mlc_reward': [-0.03705981243785511, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9586652536889763, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497630740252426, 1]}], 'average_reward': 0.7955081941824307}\n",
      "{'vehicles_speed': [21.99983737390131, 16.981787491036876, 21.99980889592728, 16.981787485763956, 21.999815996313924, 16.98165710129847, 21.999841112895776, 26.999696386024386, 16.994988237172674, 21.999838055730336], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9775320222780841, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499593434753278, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026907840414384206, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499522239818202, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9683849936716564, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499539990784809, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9637012694696041, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499602781456502, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49996204825304824, 1]}, {'proactive_mlc_reward': [-0.038758902900511615, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9564653008325851, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499595138543729, 1]}], 'average_reward': 0.7953174344633205}\n",
      "{'vehicles_speed': [21.999972209113093, 16.993529744540943, 21.999967342562385, 16.99352974266767, 21.999968555934924, 16.993483421713137, 21.999972848063255, 26.9999481159437, 16.998219499254127, 21.999972325629653], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9753320303681968, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499930522782732, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.029107830907586105, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499918356405963, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9661850028252337, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749992138983731, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9615012773737183, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499932120152302, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999351449296237, 1]}, {'proactive_mlc_reward': [-0.04045857977430347, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9542653088887831, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499930814068305, 1]}], 'average_reward': 0.7951203116047046}\n",
      "{'vehicles_speed': [16.797955618693464, 16.997701348793278, 21.999994419228138, 16.99770134812777, 21.99999462657923, 16.997684891943212, 21.99999536005346, 26.999991133625215, 16.99936745153048, 21.99999527077571], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9734531627049847, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03130782928298617, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499986048070344, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9639850043894723, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499986566448076, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9593012787244377, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499988400133608, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999988917031519, 1]}, {'proactive_mlc_reward': [-0.04215846497907583, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9520653102654919, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.749998817693923, 1]}], 'average_reward': 0.6652396247838631}\n",
      "{'vehicles_speed': [20.670844225825817, 22.81527970877631, 20.86451732507722, 23.022676157131315, 20.81922948587943, 22.716567194931017, 20.926135892573782, 24.834394404926783, 18.831469467757447, 20.904123064252232], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.01065467821632009, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.41771105645645434, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.015688490128056107, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4506237986920798, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.002834519641414346, 1]}, {'proactive_mlc_reward': [-0.02065921651265304, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4548073714698573, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9748416111151567, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4815339731434456, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.2292993006158479, 1]}, {'proactive_mlc_reward': [-0.029663545716392, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03229785804728637, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.46049849597271475, 1]}], 'average_reward': 0.6916375192014246}\n",
      "{'vehicles_speed': [21.772862916208233, 22.139321710159297, 21.80595937023388, 22.174763323086417, 21.798220211343338, 22.122452902932764, 21.816489258453558, 26.629923482961445, 17.312976584116743, 21.812727525082565], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.012788557094897148, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6932157290520582, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.017831152595616996, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.701357176829247, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02280047706912521, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6995550528358345, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9726950323171095, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7041223146133895, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4537404353701806, 1]}, {'proactive_mlc_reward': [-0.031454655289410445, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9655978956584745, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6842525412779654, 1]}], 'average_reward': 0.7629361779049687}\n",
      "{'vehicles_speed': [21.961184944732693, 19.95102902765957, 21.966840739333527, 19.95708558232499, 21.96551820813323, 19.948146346972376, 21.968640173342195, 26.93675827732669, 16.88686774105099, 21.96799733736729], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.014977257773185681, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7402962361831733, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02002149278807348, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7417091988298665, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024990439189317818, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7413795520333073, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9705041613720028, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7421600433355486, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4920947846658361, 1]}, {'proactive_mlc_reward': [-0.033140317728319504, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9634083332609228, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7418173772882142, 1]}], 'average_reward': 0.7643838416263814}\n",
      "{'vehicles_speed': [21.99336696372845, 17.50429614086724, 21.9943334724832, 17.505331134801928, 21.99410746746115, 17.503803524653613, 21.994640974584268, 26.989192733657646, 16.95980813969443, 21.994531121479362], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.017175326852045942, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7483417409321129, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02221984317251097, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7485833608127601, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.027188723833758144, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7485268668652871, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9683057214200773, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.748660243646067, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4986490917072057, 1]}, {'proactive_mlc_reward': [-0.034833023688455166, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9612099349880938, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7486313763385324, 1]}], 'average_reward': 0.7644477470465967}\n",
      "{'vehicles_speed': [21.998866492141346, 16.94851764683503, 21.99903165711619, 16.948851158367486, 21.998993035516957, 16.948358908524774, 21.99908420560739, 26.99815316533362, 16.98572126421032, 21.999065433004223], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.019374996880341167, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497166230353365, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024419561281050012, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497579142247259, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02938843069967479, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497482588792392, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9661059880139388, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497710514018472, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4997691456667024, 1]}, {'proactive_mlc_reward': [-0.03653043237600357, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9590102071205976, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497663477440675, 1]}], 'average_reward': 0.7642939767230974}\n",
      "{'vehicles_speed': [21.9998062968431, 16.98171015441722, 21.999834521594074, 16.98182863918051, 21.99982792161716, 16.981653760351982, 21.999843501512967, 26.999684397684216, 16.994927273975343, 21.999840293495954], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.02157494049205906, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499515742107752, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.0266195131091785, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499586303981145, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03158838060650878, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499569804042903, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.963906033571693, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499608753782416, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49996054971052706, 1]}, {'proactive_mlc_reward': [-0.03822951177502708, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9568102536127783, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499600732957168, 1]}], 'average_reward': 0.7641031783525118}\n",
      "{'vehicles_speed': [21.999966898409475, 16.99350226959576, 21.999971721687345, 16.993544363010127, 19.16441202414085, 16.9934822347939, 21.999973256249827, 26.99994606727741, 16.99819784120245, 21.999972708037465], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.023774930855965073, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499917246023688, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.028819504877172896, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499929304218336, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03373966363051063, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.041103006035212886, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9617060413569772, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499933140624568, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999325840967623, 1]}, {'proactive_mlc_reward': [-0.03992918471830438, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9546102615576549, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499931770087835, 1]}], 'average_reward': 0.6344762497351375}\n",
      "{'vehicles_speed': [20.68302241581858, 22.718346400823634, 20.755652791896754, 22.88372417791283, 20.8105449942333, 22.733971478966843, 20.933462615634127, 25.03801749269255, 18.848545657538327, 20.73207747665527], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9891095505211691, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4207556039546452, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.015745862875417516, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4389131979741885, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02016624716254572, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.45263624855832507, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02507451928717792, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4678144018060566, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.24880733303829183, 1]}, {'proactive_mlc_reward': [-0.02969396885193101, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9677353877396663, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.43301936916381756, 1]}], 'average_reward': 0.7070459812794045}\n",
      "{'vehicles_speed': [21.774944025597037, 22.122756948286792, 21.78735570234527, 22.15101806465996, 21.7967361338973, 22.12542709030658, 21.81774130922294, 26.66472027295886, 17.31589470404254, 21.783326958342897], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9869750658177557, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6937360063992593, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.017883960700790607, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6968389255863174, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.022307075694165884, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6991840334743253, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9728197580340245, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6854957177947254, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.45083857128730864, 1]}, {'proactive_mlc_reward': [-0.03148592790914075, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9655984627085675, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6958317395857243, 1]}], 'average_reward': 0.7784763487485518}\n",
      "{'vehicles_speed': [21.961540581842215, 19.948198304746175, 21.963661591370467, 19.953027797031748, 21.965264596758427, 19.948654600602136, 21.968854134087834, 23.456831864872356, 16.88780806216373, 21.96297312642014], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9847862616111305, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7403851454605537, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.020073382347449098, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7409153978426168, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024496963986394216, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7413161491896068, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9706299472948106, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7420313569385524, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.05702691219138645, 1]}, {'proactive_mlc_reward': [-0.03324046321646651, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9634092414786521, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7407432816050354, 1]}], 'average_reward': 0.6522809677832091}\n",
      "{'vehicles_speed': [20.633890490097727, 22.808114434268607, 20.850894679882643, 22.97903093254419, 20.634365902388488, 22.805136769134435, 20.890647582137586, 24.78912340910054, 18.880691717968247, 20.7141752985209], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9893557728372563, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4084726225244317, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.01530818167030942, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4627236699706607, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.019494917537576047, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.40859147559712206, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024323913409932885, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4726618955343964, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.2178408412167352, 1]}, {'proactive_mlc_reward': [0.9710528588130252, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03133384327709079, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.41315232302407523, 1]}], 'average_reward': 0.7128644516703491}\n",
      "{'vehicles_speed': [21.76654795754682, 22.138097249048066, 21.80363142044564, 22.16730486770686, 21.766629199913908, 22.137588401109976, 21.810424723733252, 26.62218720240493, 17.321388087559594, 21.780267686725555], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9872237322853032, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6916369893867049, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.017451017465875643, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7009078551114101, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.021626981739724518, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6916572999784769, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026468726781437142, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7026061809333131, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.44556782526286254, 1]}, {'proactive_mlc_reward': [0.9692593005952006, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9665714625145234, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6762067786876491, 1]}], 'average_reward': 0.7847022022055025}\n",
      "{'vehicles_speed': [21.960105792595307, 19.950819781661906, 21.966442920103912, 19.95581102005214, 21.960119675959998, 19.950732825536065, 21.967603815710014, 26.935436237999816, 16.88957822399148, 21.96245033289421], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9850353457554062, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7400264481488268, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.01964124877589615, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.741610730025978, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.023815372311161754, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7400299189899995, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02865929603591854, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7419009539275034, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49188733939993545, 1]}, {'proactive_mlc_reward': [0.9675731386693319, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9643835077640543, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7404320685139547, 1]}], 'average_reward': 0.7863004852916922}\n",
      "{'vehicles_speed': [21.9931825493248, 17.504260383188097, 21.994265489857348, 17.5051133271052, 21.993184921828483, 17.504245523409264, 21.994463873258063, 26.98896681269097, 16.960771077699178, 21.993583203677492], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9828373303608099, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7482956373312, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.021839579421710945, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.748566372464337, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026013388396409647, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7482962304571208, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03085768443246567, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7486159683145157, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4986207051621978, 1]}, {'proactive_mlc_reward': [0.9658802579547028, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9621853853525304, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.748394409834539, 1]}], 'average_reward': 0.7863829382944222}\n",
      "{'vehicles_speed': [21.998834977889466, 16.948506124450248, 21.999020039685274, 16.948780973049214, 21.99883538332243, 16.948501336105654, 21.9990539410744, 26.99811455809846, 16.986063361770555, 21.998903445004494], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9806376695065238, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497087444723665, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024039294148721274, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497550099213184, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02821304936872001, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497088458306074, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03305740902839669, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497634852686001, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49976431935413235, 1]}, {'proactive_mlc_reward': [0.9641827871831099, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.959985704640129, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497258508444604, 1]}], 'average_reward': 0.7862322954853206}\n",
      "{'vehicles_speed': [21.999800911428228, 16.98170606092449, 21.999832536311814, 16.98180370483788, 21.999800980711953, 16.98170435979628, 21.999838329660353, 26.999677800161955, 16.99504880904836, 21.999812611652647], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9784377274625361, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499502278570569, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026239245398923687, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499581340779535, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.030412991432876634, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499502451779883, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.035257361965081536, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499595824150882, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999597250192398, 1]}, {'proactive_mlc_reward': [0.9624836857278376, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9577857591906738, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499531528356433, 1]}], 'average_reward': 0.7860420312583962}\n",
      "{'vehicles_speed': [21.999965978105433, 16.993500815323657, 19.164412893569068, 16.993535504726687, 21.99996598994521, 16.99350021097342, 21.999972372441064, 26.99994493983848, 16.99824101828317, 21.99996797753613], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9762377373665367, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499914945263582, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02840016654983868, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.04110322339226702, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03261298153232263, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499914974863024, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.037457353922514695, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499930931102661, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999311747980757, 1]}, {'proactive_mlc_reward': [0.9607840049487612, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9555857685126309, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499919943834552, 1]}], 'average_reward': 0.6564150433902287}\n",
      "{'vehicles_speed': [20.651528602805005, 22.901461841083183, 20.825585834617332, 23.00899658671074, 20.777985383702415, 22.949808932805823, 20.6583543256211, 25.03376377691501, 18.653693659877444, 20.919587384495077], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.01098491958820903, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4128821507012512, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.015678531932132915, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.44091850016211875, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0011245733388425272, 1]}, {'proactive_mlc_reward': [0.9792641728710736, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4444963459256037, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.025263560835909724, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.39924491963598996, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.25422047211437615, 1]}, {'proactive_mlc_reward': [-0.030150616847331616, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.032863733803403614, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4643544850297756, 1]}], 'average_reward': 0.6911128029473012}\n",
      "{'vehicles_speed': [21.769562103489502, 22.154049222605536, 21.799306436557824, 22.172425645446804, 21.791172079533567, 22.162311171759328, 21.770728539211593, 26.66399336297904, 17.282596790148897, 21.815370195468557], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.013117837578167956, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6923905258723755, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.017778827390096785, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6809252945760944, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9771249640728235, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6977930198833917, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9726445497955977, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6738432876455516, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4579991703723798, 1]}, {'proactive_mlc_reward': [-0.03193288265951531, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9650312417575504, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6849077827543288, 1]}], 'average_reward': 0.7782361693818725}\n",
      "{'vehicles_speed': [21.960620874674362, 19.953545786261945, 21.965703831242536, 19.956686100720027, 21.964313765330843, 19.9549576561674, 21.960820204815715, 26.94258041897682, 16.98988233818677, 21.96844893864425], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.015306374051896865, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7401552186685905, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.01996772504620068, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7412445925698217, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9749353525739712, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7410784413327107, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9704570674412221, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7400249678261588, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4928225523721026, 1]}, {'proactive_mlc_reward': [-0.033633120341199765, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9628415484645432, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7419301617943175, 1]}], 'average_reward': 0.7799723300447801}\n",
      "{'vehicles_speed': [21.993270570791978, 17.504726225301777, 21.994139188266598, 17.50526286809569, 21.99390164235693, 17.504967497257446, 21.993304633967945, 26.990187669165977, 16.996405555285516, 21.99460829482434], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.017504415070129807, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7483176426979945, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.0221660092591134, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7485333983566616, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9727371278465928, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7484754105892328, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9682590260981686, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7483247712638041, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49877345864574707, 1]}, {'proactive_mlc_reward': [-0.03533246801948989, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9606431277327871, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7486506686319583, 1]}], 'average_reward': 0.7800479145219213}\n",
      "{'vehicles_speed': [21.9988500197226, 16.94865623520163, 21.998998456229405, 16.94882916042813, 21.99895786242826, 16.948733981531323, 21.998855840718605, 26.998323188106205, 16.99872302187561, 21.99907862102091], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.01970408030319397, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497125049306499, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02436571762950837, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497496035916145, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9705374312197972, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497394656070648, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9660593592434862, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497139498028487, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49979039851327567, 1]}, {'proactive_mlc_reward': [-0.03703223627283088, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9584433960262272, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497696447401525, 1]}], 'average_reward': 0.7798957559243471}\n",
      "{'vehicles_speed': [21.999803481900543, 16.98175938992548, 21.999828847953143, 16.98182082409653, 21.99982191095013, 16.981787010426054, 21.99980447664027, 26.999713452575673, 16.999546335175612, 21.99984254717284], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.02190402309546329, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499508704751356, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026565667805455884, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499572119103242, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9683374830627084, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499554777375321, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9638594161621858, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499511190827732, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999641815719591, 1]}, {'proactive_mlc_reward': [-0.03873215394150087, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.956243441862348, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499606367148779, 1]}], 'average_reward': 0.7797052233631542}\n",
      "{'vehicles_speed': [21.999966417368913, 16.993519761217403, 21.999970752128863, 16.993541586589267, 21.999969566676665, 16.993529573797044, 21.99996658735823, 26.99995103241652, 16.999838829053562, 21.999973093164336], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.024104013319335187, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499916043422283, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.028765659291201246, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499926880316359, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.966137491922052, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499923916691662, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9616594258888329, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.749991646838982, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999938790520648, 1]}, {'proactive_mlc_reward': [-0.040432124692113075, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9540434496951116, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499932732905004, 1]}], 'average_reward': 0.779508136929581}\n",
      "{'vehicles_speed': [21.99999426112346, 16.99769780207417, 17.886809028869543, 16.997705555851077, 21.999994799303106, 16.997701288134056, 21.999994290172634, 26.999991632016105, 16.999942741705816, 21.999995401938357], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [-0.026304011648709904, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499985652808654, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03089899186845014, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.0, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9639374934360097, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499986998257766, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9594594275510019, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499985725431539, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999989540020131, 1]}, {'proactive_mlc_reward': [-0.04213211430084785, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.951843451033638, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499988504845847, 1]}], 'average_reward': 0.6496234798602687}\n",
      "{'vehicles_speed': [20.944632151957446, 22.724765317608014, 20.67875671679209, 22.784056397061327, 20.804202580709788, 22.72652015591389, 20.766586747588196, 24.979032304412844, 18.573412560861627, 20.84640657145954], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9886903191430303, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.4861580379893615, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.01581676039362424, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4043276633535795, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9793808666310232, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.451050645177447, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.025342366106419288, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.441646686897049, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.24146593207248568, 1]}, {'proactive_mlc_reward': [0.9702179011590216, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03215045180222645, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.446108775259189, 1]}], 'average_reward': 0.7289575407020383}\n",
      "{'vehicles_speed': [21.81965005156682, 22.12385386564429, 21.774215067820954, 22.133986013541143, 21.795652290047002, 22.124153746864433, 21.78922418673086, 26.65464039826465, 17.268877694864237, 21.802864455520403], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9865428202170068, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7049125128917053, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.01790967479058371, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6747070824079779, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9772403536135834, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6989130725117505, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.027481007860070714, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6973060466827148, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4495891334908837, 1]}, {'proactive_mlc_reward': [0.9684396290670618, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9657482055240328, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6818072919594202, 1]}], 'average_reward': 0.8002417872148253}\n",
      "{'vehicles_speed': [21.969180315697336, 19.94838575501693, 21.96141601153474, 19.95011721988399, 21.965079380596237, 19.948437001189234, 21.963980893368547, 26.940982107348262, 16.985240523238975, 21.966311854821818], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9843517920328546, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7422950789243341, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02009732980135653, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7401737614375525, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9750505192390163, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7412698451490591, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02967052245767245, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7409952233421366, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4925801365601088, 1]}, {'proactive_mlc_reward': [0.9667402381396543, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9635591316447905, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7413964409674048, 1]}], 'average_reward': 0.8018659066148363}\n",
      "{'vehicles_speed': [21.99473327855778, 17.503844436671706, 21.993406450326336, 17.504140323646155, 21.99403247699804, 17.50385319403962, 21.99384475845494, 26.989914536513385, 16.994756483838707, 21.99424309234267], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9821533252106263, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7486833196394453, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.022295400774661522, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7483502239408866, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9728522564248004, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.74850811924951, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.031868730625767276, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7484611896137352, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4987391686738105, 1]}, {'proactive_mlc_reward': [0.9650411897357142, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9613608171938732, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7485593729607736, 1]}], 'average_reward': 0.8019338127311851}\n",
      "{'vehicles_speed': [21.999099979270476, 16.94837209181928, 21.998873239936344, 16.948467437033365, 21.998980220529106, 16.948374913751945, 21.998948141638667, 26.998276512949385, 16.99813716555276, 21.999016212213533], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.979953587212669, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497749948176189, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02449507269429682, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497182995963492, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9706525532894124, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497450551322764, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.034068424422776244, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497370354096669, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49978456370426905, 1]}, {'proactive_mlc_reward': [0.9633415278038856, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9591611036546686, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497540425766802, 1]}], 'average_reward': 0.801780482364661}\n",
      "{'vehicles_speed': [21.999846197046402, 16.98165844390676, 21.999807449961875, 16.981692316663835, 21.999825731686506, 16.98165944643888, 21.999820249781557, 26.999705476340516, 16.99933820130022, 21.999831882241924], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9777536319857356, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499615492616005, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02669501664115033, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499518624130923, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9684526040200817, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499564329216266, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03626837209628768, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499550624453892, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999631845415431, 1]}, {'proactive_mlc_reward': [0.9616416479074603, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9569611525954198, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499579704824368, 1]}], 'average_reward': 0.8015897511343365}\n",
      "{'vehicles_speed': [21.999973716884778, 16.993483898694016, 21.999967095463905, 16.993495932477597, 21.999970219595557, 16.993484254857957, 21.999969282802496, 26.999949669371777, 16.999764886504177, 21.999971270653116], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9755536396369259, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499934292211945, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.028895007062416152, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499917738654007, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9662526126893562, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499925548988893, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03846836315430641, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749992320700624, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999370867146986, 1]}, {'proactive_mlc_reward': [0.9599416905759808, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9547611609587286, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499928176626982, 1]}], 'average_reward': 0.8013926308695684}\n",
      "{'vehicles_speed': [21.99999550852484, 16.99768506139752, 21.99999437700192, 16.99768933657202, 21.99999491087926, 16.997685187929875, 21.999994750792347, 26.999991399087794, 16.99991647255285, 21.999995090492625], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9733536409444243, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.74999887713121, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.031095005425523847, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499985942504752, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9640526141708333, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499987277198148, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.04066836162622703, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499986876980866, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999989248859742, 1]}, {'proactive_mlc_reward': [0.9582417057345857, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.952561162387919, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499987726231518, 1]}], 'average_reward': 0.8011944185923359}\n",
      "{'vehicles_speed': [21.99999923245974, 16.99917758480392, 21.999999039095787, 16.999179103621078, 21.999999130329144, 16.999177629756357, 21.99999910297217, 26.999998530205296, 16.999970325674404, 21.999999161022952], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9711536411678604, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499998081149348, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03329500514579821, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499997597739467, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9618526144240003, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749999782582286, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.04286836136509624, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499997757430421, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999981627566203, 1]}, {'proactive_mlc_reward': [0.9565417111198978, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9503611626321509, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.749999790255738, 1]}], 'average_reward': 0.8009960196239259}\n",
      "{'vehicles_speed': [21.9999998688364, 16.999707825186366, 21.999999835792774, 16.999708364767983, 21.999999851383482, 16.99970784115637, 21.999999846708494, 26.99999974882938, 16.999989457769512, 21.99999985662869], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.968953641206043, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999672091002, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.035495005097996406, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999589481936, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9596526144672636, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999628458704, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.04506836132047207, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999616771236, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999999686036727, 1]}, {'proactive_mlc_reward': [0.9548417130331073, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9481611626738872, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999641571726, 1]}], 'average_reward': 0.8007975887240357}\n",
      "{'vehicles_speed': [21.999999977585688, 16.99989620069993, 21.99999997193892, 16.99989639239405, 21.999999974603185, 16.9998962063735, 21.99999997380429, 26.999999957077897, 16.999996254721168, 21.999999975499534], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9667536412125679, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749999994396422, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03769500508982763, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999929847299, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9574526144746567, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999936507962, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.047268361312846306, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999934510724, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999999946347371, 1]}, {'proactive_mlc_reward': [0.9531417137128024, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9459611626810195, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999938748836, 1]}], 'average_reward': 0.8005991523574286}\n",
      "{'vehicles_speed': [21.99999999616966, 16.99996312380742, 21.999999995204693, 16.999963191909508, 21.99999999565998, 16.999963125823037, 21.99999999552346, 26.999999992665114, 16.999998669435886, 21.999999995813155], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9645536412136829, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999990424149, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03989500508843169, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999988011732, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9552526144759201, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749999998914995, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.04946836131154316, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749999998880865, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999999990831392, 1]}, {'proactive_mlc_reward': [0.9514417139542739, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9437611626822383, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999989532888, 1]}], 'average_reward': 0.8004007150530702}\n",
      "{'vehicles_speed': [21.999999999345437, 16.99998689920281, 21.999999999180538, 16.999986923397056, 21.999999999258346, 16.99998689991888, 21.999999999235015, 26.999999998746553, 16.999999527297984, 21.99999999928452], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9623536412138735, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999998363593, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.042095005088193145, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999997951345, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.953052614476136, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999998145865, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.05166836131132047, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999998087539, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999999998433191, 1]}, {'proactive_mlc_reward': [0.9497417140400601, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9415611626824465, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999998211297, 1]}], 'average_reward': 0.8002022775871988}\n",
      "{'vehicles_speed': [21.999999999888146, 16.999995345753586, 21.999999999859966, 16.999995354348943, 21.99999999987326, 16.99999534600798, 21.999999999869274, 26.9999999997858, 16.999999832065814, 21.999999999877733], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9601536412139061, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999720366, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.04429500508815237, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999999649916, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9508526144761729, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999683151, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.05386836131128242, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999673186, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.499999999973225, 1]}, {'proactive_mlc_reward': [0.948041714070537, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9393611626824822, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999999694333, 1]}], 'average_reward': 0.8000038400932779}\n",
      "{'vehicles_speed': [21.999999999980886, 16.999998346512097, 21.99999999997607, 16.99999834956572, 21.999999999978343, 16.999998346602478, 21.999999999977657, 26.999999999963396, 16.999999940338967, 21.999999999979106], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9579536412139116, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999952216, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.04649500508814541, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999999940172, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9486526144761792, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999945857, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.05606836131127592, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999944142, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999999999542455, 1]}, {'proactive_mlc_reward': [0.9463417140813642, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9371611626824882, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999999947766, 1]}], 'average_reward': 0.7998054025944047}\n",
      "{'vehicles_speed': [21.99999999999673, 16.99999941257467, 21.999999999995907, 16.999999413659513, 21.999999999996298, 16.999999412606776, 21.999999999996177, 26.999999999993747, 16.999999978804563, 21.99999999999643], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9557536412139126, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999991829, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.04869500508814422, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999999989768, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9464526144761803, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999990745, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.058268361311274816, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499999999990443, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999999999992184, 1]}, {'proactive_mlc_reward': [0.9446417140852108, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9349611626824893, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999999991074, 1]}], 'average_reward': 0.7996069650946284}\n",
      "{'vehicles_speed': [16.768070177398958, 16.999999791308714, 19.16444444444367, 16.999999791694115, 21.999999999999364, 16.999999791320118, 21.999999999999346, 26.999999999998934, 16.999999992470016, 21.99999999999939], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 2, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9537993267919896, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.050848344232853046, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.0411111111109177, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9442526144761805, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.749999999999841, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9395609650669736, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7341081031477499, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4999999999998668, 1]}, {'proactive_mlc_reward': [0.9429417140865773, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9327611626824894, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499999999998472, 1]}], 'average_reward': 0.5495711738214789}\n",
      "{'vehicles_speed': [20.774011193088143, 22.943447360131785, 20.768899806582642, 22.96231541624317, 20.65228007979162, 22.943539411515847, 20.799138595513014, 24.790876543821657, 18.65870586011142, 20.778689787653743], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9888683613421657, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.44350279827203565, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.015474810991162428, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.44222495164566045, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.01985858037248957, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.41307001994790493, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024154370952254416, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.44978464887825353, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.21805884947573473, 1]}, {'proactive_mlc_reward': [0.9716182640854147, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9693632222979656, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4292294769422256, 1]}], 'average_reward': 0.7285735997417869}\n",
      "{'vehicles_speed': [21.790492937115427, 22.16122405383561, 21.78961946129901, 22.164448382635314, 21.769690522065112, 22.16123978433413, 21.794786914556553, 26.622486792502485, 17.283453316198475, 21.791292453881272], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9867293502468074, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6976232342788569, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.017613567811879442, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.6974048653247529, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02199153574595316, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.692422630516278, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026294632053111805, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.6986967286391383, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4456049374274573, 1]}, {'proactive_mlc_reward': [0.96983574893278, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9672248184197314, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.697692855739068, 1]}], 'average_reward': 0.784838566918103}\n",
      "{'vehicles_speed': [21.96419770788195, 19.954771880504588, 21.964048441141692, 19.955322880361024, 21.96064281989804, 19.954774568661705, 21.964931498106388, 26.935487434422697, 16.99017214121952, 21.964334335890612], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9845397725330534, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7410494269704877, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.019803102073088885, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.741012110285423, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02418007860808319, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7401607049745103, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.028484423378098808, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.741232874526597, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49189373488343335, 1]}, {'proactive_mlc_reward': [0.9681354583855764, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9650352077173022, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.741082619781154, 1]}], 'average_reward': 0.7863096159866453}\n",
      "{'vehicles_speed': [21.99388180950438, 17.504935750382387, 21.993856301574645, 17.505029909775132, 21.993274320972517, 17.504936209756817, 21.994007205620417, 26.988975561557293, 16.99650851197636, 21.993905157623573], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9823415535791508, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.748470452376095, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.02200131360146291, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7484640753936613, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026378120718018715, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7483185802431294, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03068267883564796, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7485018014051041, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.4986217987522483, 1]}, {'proactive_mlc_reward': [0.966436092022652, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.962836982017013, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7484762822665836, 1]}], 'average_reward': 0.7863889642287252}\n",
      "{'vehicles_speed': [21.998954473227098, 16.948723751569005, 21.998950114222016, 16.94875409304475, 21.998850660584328, 16.94872389959564, 21.998975901947997, 26.998116053176787, 16.99875959871916, 21.998958463145968], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9801418579389741, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497386183067745, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.024201007972704063, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497375285555039, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.028577786137642006, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497126651460819, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03288238071386831, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7497439754869992, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49976450623886537, 1]}, {'proactive_mlc_reward': [0.9647363171313262, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9606372852157183, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7497396157334366, 1]}], 'average_reward': 0.7862379538945137}\n",
      "{'vehicles_speed': [21.999821331775525, 16.981783376084966, 21.999820586872843, 16.98179415533012, 21.999803591416267, 16.981783428673555, 21.99982499369181, 26.999678055653252, 16.999559329624766, 21.999822013605716], 'crashed': False, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.977941909950487, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499553329438813, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.026400955744345016, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499551467182108, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.030777728961792088, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499508978540668, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03508232976836369, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499562484229525, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49995975695565154, 1]}, {'proactive_mlc_reward': [0.9630363971044168, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9584373370287488, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499555034010337, 1]}], 'average_reward': 0.7860476216269918}\n",
      "{'vehicles_speed': [21.999969467702535, 16.993528282645165, 21.99996934040743, 16.993532112126864, 21.99996643608386, 16.993528301328016, 21.999970093480947, 26.999944983498935, 16.99984344551831, 21.999969584219293], 'crashed': True, 'action': array([1, 4, 0, 4, 1, 4, 1, 0, 4, 2], dtype=int64), 'rewards': [{'proactive_mlc_reward': [0.9757419188386426, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499923669256336, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.028600946819132934, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499923351018571, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03297469322941089, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499916090209648, 1]}, {'target_speed_reward': [1, 2.5], 'collision_penalty': [-1, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [-0.03728232106237634, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.7499925233702367, 1]}, {'target_speed_reward': [0, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.49999312293736464, 1]}, {'proactive_mlc_reward': [0.9613364255160062, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [0, 1], 'high_speed_reward': [0.0, 1]}, {'proactive_mlc_reward': [0.9562373458829856, 2.5], 'collision_penalty': [0, 10], 'lane change penalty': [-1, 1], 'high_speed_reward': [0.7499923960548207, 1]}], 'average_reward': 0.660850616726423}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "###MODEL TESTING###\n",
    "model = PPO.load('Training/Saved Models/A2C_model', env=env)\n",
    "for episode in trange(10, desc=\"Test episodes\"):\n",
    "    env.configure({\"simulation_frequency\":15,})\n",
    "    obs, done = env.reset(), False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        print(info)\n",
    "        env.render('human')\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('HighwayEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3ad5ee2ef26874e04e7cedb1b85599df4bcd7c0a1b3970111d4d655b242d185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
